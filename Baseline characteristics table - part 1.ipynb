{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline characteristics table - part 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * This code belongs to the paper \"Early Prediction of End Stage Kidney Disease Based on Cumulative Estimated Glomerular Filtration Rate Velocity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_data = pd.read_csv(\"DIAGNOSIS_2.csv\")\n",
    "datapool_ESRD = pd.read_csv('Final_ESRD_group_done_pandas.csv')\n",
    "full_date_dataset = pd.read_csv('merged_dataset_dates_timedeltas_full.csv')\n",
    "\n",
    "\n",
    "datapool_ESRD = pd.read_csv('Final_ESRD_group_done_pandas.csv')\n",
    "datapool_ESRD = datapool_ESRD.drop(columns=datapool_ESRD.columns[0])\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "datapool_ESRD_dropped = datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_ESRD_dropped = datapool_ESRD_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD_dates = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_dates = datapool_ESRD_dates.reset_index()\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dates, on = 'patient_sk', how='left')\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_x'] - datapool_ESRD['Date_y']\n",
    "datapool_ESRD = datapool_ESRD.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop('Date_y', axis = 1)\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "datapool_ESRD_patients = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_patients = datapool_ESRD_patients.reset_index()\n",
    "\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD.merge(datapool_ESRD_patients, on=['patient_sk', 'Date'], how ='inner')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR.drop_duplicates('patient_sk')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR[datapool_ESRD_patients_eGFR['eGFR_EPI']>=60]\n",
    "\n",
    "datapool_ESRD_new = datapool_ESRD.merge(datapool_ESRD_patients_eGFR['patient_sk'], on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_ESRD = datapool_ESRD_new\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = full_date_dataset.merge(diagnosis_data, on = 'patient_sk' , how = 'inner')\n",
    "merged_dataset = merged_dataset.rename(columns={'eGFR_EPI': 'Trigger_eGFR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing NaN and NaT (pd.null) by 0\n",
    "pp = []\n",
    "for i in range(len(list(merged_dataset['patient_sk']))):\n",
    "   \n",
    "    if np.isnan(merged_dataset.New_label[i]) == False:\n",
    "        pp.append(merged_dataset.patient_sk[0])\n",
    "        \n",
    "\n",
    "trigger_below_20 = list(np.array(list(merged_dataset['patient_sk']))[np.array(list(merged_dataset['Trigger_eGFR']))<20])\n",
    "print('trigger_below_20:', len(trigger_below_20))\n",
    "\n",
    "a = np.array(list(merged_dataset['Trigger_eGFR']))<40 \n",
    "b = np.array(list(merged_dataset['Trigger_eGFR']))>=20\n",
    "pa = np.array(list(merged_dataset['patient_sk']))[a]\n",
    "pb = np.array(list(merged_dataset['patient_sk']))[b]                  \n",
    "trigger_between_20_40 = list(np.intersect1d(pb, pa))\n",
    "print('trigger_between_20_40:', len(trigger_between_20_40))\n",
    "\n",
    "a = np.array(list(merged_dataset['Trigger_eGFR']))<60 \n",
    "b = np.array(list(merged_dataset['Trigger_eGFR']))>=40\n",
    "pa = np.array(list(merged_dataset['patient_sk']))[a]\n",
    "pb = np.array(list(merged_dataset['patient_sk']))[b]                  \n",
    "trigger_between_40_60 = list(np.intersect1d(pb, pa))\n",
    "print('trigger_between_40_60:', len(trigger_between_40_60))\n",
    "\n",
    "trigger_above_60 = np.array(list(merged_dataset['patient_sk']))[np.array(list(merged_dataset['Trigger_eGFR']))>=60]\n",
    "print('trigger_above_60:', len(trigger_above_60))\n",
    "\n",
    "no_trigger = list(set(list(merged_dataset['patient_sk'])) - (set(trigger_below_20)) - set(trigger_between_20_40) - set(trigger_between_40_60) - set(trigger_above_60))\n",
    "print('no_trigger:', len(no_trigger))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having dialysis AFTER trigger date\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_dialysis'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_dialysis'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_dialysis = list(merged_dataset['Diagnosis_admission_date_dialysis'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_dialysis)):\n",
    "    if pd.isnull(Diagnosis_admission_date_dialysis[i]):\n",
    "        Diagnosis_admission_date_dialysis[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_dialysis)):\n",
    "    if Diagnosis_admission_date_dialysis[i] >= Trigger_date[i] and Diagnosis_admission_date_dialysis[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_dialysis: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_dialysis)):\n",
    "    if Diagnosis_admission_date_dialysis[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_dialysis[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having transplant AFTER trigger date\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_transplant'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_transplant'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_transplant = list(merged_dataset['Diagnosis_admission_date_transplant'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_transplant)):\n",
    "    if pd.isnull(Diagnosis_admission_date_transplant[i]):\n",
    "        Diagnosis_admission_date_transplant[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_transplant)):\n",
    "    if Diagnosis_admission_date_transplant[i] >= Trigger_date[i] and Diagnosis_admission_date_transplant[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_transplant: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_transplant)):\n",
    "    if Diagnosis_admission_date_transplant[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_transplant[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Nicotine_Tobacco_dependency = list(merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Nicotine_Tobacco_dependency)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Nicotine_Tobacco_dependency[i]):\n",
    "        Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Nicotine_Tobacco_dependency)):\n",
    "    if Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] <= Trigger_date[i] and Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Nicotine_Tobacco_dependency: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Nicotine_Tobacco_dependency)):\n",
    "    if Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Nicotine_Tobacco_dependency <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Nicotine_Tobacco_dependency) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Hypertension'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypertension'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypertension = list(merged_dataset['Diagnosis_admission_date_Hypertension'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypertension[i]):\n",
    "        Diagnosis_admission_date_Hypertension[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if Diagnosis_admission_date_Hypertension[i] <= Trigger_date[i] and Diagnosis_admission_date_Hypertension[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Hypertension: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if Diagnosis_admission_date_Hypertension[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypertension[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Hypertension <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Hypertension) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Diabetes'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Diabetes'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Diabetes = list(merged_dataset['Diagnosis_admission_date_Diabetes'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Diabetes[i]):\n",
    "        Diagnosis_admission_date_Diabetes[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if Diagnosis_admission_date_Diabetes[i] <= Trigger_date[i] and Diagnosis_admission_date_Diabetes[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Diabetes: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if Diagnosis_admission_date_Diabetes[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Diabetes[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Diabetes <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Diabetes) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Coronary_Artery_Disease = list(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Coronary_Artery_Disease[i]):\n",
    "        Diagnosis_admission_date_Coronary_Artery_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if Diagnosis_admission_date_Coronary_Artery_Disease[i] <= Trigger_date[i] and Diagnosis_admission_date_Coronary_Artery_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Coronary_Artery_Disease: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if Diagnosis_admission_date_Coronary_Artery_Disease[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Coronary_Artery_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Coronary_Artery_Disease <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Coronary_Artery_Disease) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Cerebrovascular_Disease = list(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Cerebrovascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Cerebrovascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if Diagnosis_admission_date_Cerebrovascular_Disease[i] <= Trigger_date[i] and Diagnosis_admission_date_Cerebrovascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Cerebrovascular_Disease: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if Diagnosis_admission_date_Cerebrovascular_Disease[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Cerebrovascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Cerebrovascular_Disease <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Cerebrovascular_Disease) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Peripheral_Vascular_Disease = list(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Peripheral_Vascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Peripheral_Vascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if Diagnosis_admission_date_Peripheral_Vascular_Disease[i] <= Trigger_date[i] and Diagnosis_admission_date_Peripheral_Vascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Peripheral_Vascular_Disease: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if Diagnosis_admission_date_Peripheral_Vascular_Disease[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Peripheral_Vascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Peripheral_Vascular_Disease <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Peripheral_Vascular_Disease) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Sickle_Cell_Trait'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Sickle_Cell_Trait'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Sickle_Cell_Trait = list(merged_dataset['Diagnosis_admission_date_Sickle_Cell_Trait'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Sickle_Cell_Trait)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Sickle_Cell_Trait[i]):\n",
    "        Diagnosis_admission_date_Sickle_Cell_Trait[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Sickle_Cell_Trait)):\n",
    "    if Diagnosis_admission_date_Sickle_Cell_Trait[i] <= Trigger_date[i] and Diagnosis_admission_date_Sickle_Cell_Trait[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Sickle_Cell_Trait: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Sickle_Cell_Trait)):\n",
    "    if Diagnosis_admission_date_Sickle_Cell_Trait[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Sickle_Cell_Trait[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Sickle_Cell_Trait <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Sickle_Cell_Trait) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Hx_of_Cancer'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hx_of_Cancer'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hx_of_Cancer = list(merged_dataset['Diagnosis_admission_date_Hx_of_Cancer'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hx_of_Cancer)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hx_of_Cancer[i]):\n",
    "        Diagnosis_admission_date_Hx_of_Cancer[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hx_of_Cancer)):\n",
    "    if Diagnosis_admission_date_Hx_of_Cancer[i] <= Trigger_date[i] and Diagnosis_admission_date_Hx_of_Cancer[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Hx_of_Cancer: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hx_of_Cancer)):\n",
    "    if Diagnosis_admission_date_Hx_of_Cancer[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hx_of_Cancer[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Hx_of_Cancer <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Hx_of_Cancer) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypercholesterolemia = list(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypercholesterolemia[i]):\n",
    "        Diagnosis_admission_date_Hypercholesterolemia[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if Diagnosis_admission_date_Hypercholesterolemia[i] <= Trigger_date[i] and Diagnosis_admission_date_Hypercholesterolemia[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Hypercholesterolemia: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if Diagnosis_admission_date_Hypercholesterolemia[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypercholesterolemia[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_Hypercholesterolemia <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_Hypercholesterolemia) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities = list(merged_dataset['Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities)):\n",
    "    if pd.isnull(Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i]):\n",
    "        Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities)):\n",
    "    if Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i] <= Trigger_date[i] and Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities)):\n",
    "    if Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i] >= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "print('no_trigger: ',len(list(set(count_list) & set(no_trigger))))\n",
    "\n",
    "\n",
    "merged_dataset[(merged_dataset.Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities <= merged_dataset.Diagnosis_admission_date_ESRD) & (np.isnan(merged_dataset.Diagnosis_admission_date_History_of_Urinary_Tract_Abnormalities) == False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_trigger = datapool_ESRD.merge(pd.DataFrame({'patient_sk' : no_trigger}), on = 'patient_sk', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))\n",
    "\n",
    "dataaa_ESRD = []\n",
    "for patient in patients_list_ESRD:\n",
    "    data = datapool_ESRD.loc[datapool_ESRD['patient_sk'] == patient]\n",
    "    data = data.sort_values(by=['Date'])\n",
    "    data = data.reset_index()\n",
    "    data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "    data = data.drop('index', axis =1)    \n",
    "    dataaa_ESRD.append(data)\n",
    "print(len(dataaa_ESRD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ages = []\n",
    "Genders = []\n",
    "Races = []\n",
    "\n",
    "i = 0\n",
    "count_list = []\n",
    "for patient in dataaa_ESRD:\n",
    "    \n",
    "    m_table = merged_dataset[merged_dataset.patient_sk == patient.patient_sk[0]]\n",
    "    if np.isnan(m_table.New_label).values[0] == False:\n",
    "        \n",
    "        patient.Date = pd.to_datetime(patient.Date)\n",
    "        ppp_date = pd.to_datetime(merged_dataset[merged_dataset.patient_sk == patient.patient_sk[0]].Trigger_date.values)\n",
    "\n",
    "        Trigger_index = list(patient.Date).index(ppp_date)\n",
    "\n",
    "        if pd.isnull(Trigger_index) == False:\n",
    "            Ages.append(patient.Age[int(Trigger_index)])\n",
    "            Genders.append(patient.Gender[int(Trigger_index)])\n",
    "            Races.append(patient.Race[int(Trigger_index)])\n",
    "            count_list.append(patient.patient_sk[0])\n",
    "        i = i + 1\n",
    "    \n",
    "\n",
    "trigger_below_20 = list(set(count_list) & set(trigger_below_20))\n",
    "trigger_between_20_40 = list(set(count_list) & set(trigger_between_20_40))\n",
    "trigger_between_40_60 = list(set(count_list) & set(trigger_between_40_60))\n",
    "trigger_above_60 = list(set(count_list) & set(trigger_above_60))\n",
    "\n",
    "print(len(trigger_below_20), len(trigger_between_20_40), len(trigger_between_40_60), len(trigger_above_60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ages\n",
    "\n",
    "trigger_below_20_age_mean = 0\n",
    "trigger_between_20_40_age_mean = 0\n",
    "trigger_between_40_60_age_mean = 0\n",
    "trigger_above_60_age_mean = 0\n",
    "\n",
    "for patient_sk in count_list:\n",
    "    if patient_sk in trigger_below_20:\n",
    "        trigger_below_20_age_mean = trigger_below_20_age_mean + (Ages[count_list.index(patient_sk)])/len(trigger_below_20)\n",
    "    elif patient_sk in trigger_between_20_40:\n",
    "        trigger_between_20_40_age_mean = trigger_between_20_40_age_mean + (Ages[count_list.index(patient_sk)])/len(trigger_between_20_40)    \n",
    "    elif patient_sk in trigger_between_40_60:\n",
    "        trigger_between_40_60_age_mean = trigger_between_40_60_age_mean + (Ages[count_list.index(patient_sk)])/len(trigger_between_40_60)\n",
    "    elif patient_sk in trigger_above_60:\n",
    "        trigger_above_60_age_mean = trigger_above_60_age_mean + (Ages[count_list.index(patient_sk)])/len(trigger_above_60)\n",
    "        \n",
    "print('trigger_below_20_age_mean = ', trigger_below_20_age_mean)\n",
    "print('trigger_between_20_40_age_mean = ', trigger_between_20_40_age_mean)\n",
    "print('trigger_between_40_60_age_mean = ', trigger_between_40_60_age_mean)\n",
    "print('trigger_above_60_age_mean = ', trigger_above_60_age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD_age = datapool_ESRD.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "np.mean(datapool_ESRD_age.Age)\n",
    "\n",
    "datapool_ESRD_age = data_no_trigger.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "np.mean(datapool_ESRD_age.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender\n",
    "\n",
    "trigger_below_20_Female_count = 0\n",
    "trigger_between_20_40_Female_count = 0\n",
    "trigger_between_40_60_Female_count = 0\n",
    "trigger_above_60_Female_count = 0\n",
    "\n",
    "trigger_below_20_Male_count = 0\n",
    "trigger_between_20_40_Male_count = 0\n",
    "trigger_between_40_60_Male_count = 0\n",
    "trigger_above_60_Male_count = 0\n",
    "\n",
    "for patient_sk in count_list:\n",
    "    if patient_sk in trigger_below_20:\n",
    "        if Genders[count_list.index(patient_sk)] == 'Female':\n",
    "            trigger_below_20_Female_count = trigger_below_20_Female_count + 1\n",
    "        elif Genders[count_list.index(patient_sk)] == 'Male':\n",
    "            trigger_below_20_Male_count = trigger_below_20_Male_count + 1\n",
    "\n",
    "    elif patient_sk in trigger_between_20_40:\n",
    "        if Genders[count_list.index(patient_sk)] == 'Female':\n",
    "            trigger_between_20_40_Female_count = trigger_between_20_40_Female_count + 1\n",
    "        elif Genders[count_list.index(patient_sk)] == 'Male':\n",
    "            trigger_between_20_40_Male_count = trigger_between_20_40_Male_count + 1\n",
    "\n",
    "    elif patient_sk in trigger_between_40_60:\n",
    "        if Genders[count_list.index(patient_sk)] == 'Female':\n",
    "            trigger_between_40_60_Female_count = trigger_between_40_60_Female_count + 1\n",
    "        elif Genders[count_list.index(patient_sk)] == 'Male':\n",
    "            trigger_between_40_60_Male_count = trigger_between_40_60_Male_count + 1\n",
    "            \n",
    "    elif patient_sk in trigger_above_60:\n",
    "        if Genders[count_list.index(patient_sk)] == 'Female':\n",
    "            trigger_above_60_Female_count = trigger_above_60_Female_count + 1\n",
    "        elif Genders[count_list.index(patient_sk)] == 'Male':\n",
    "            trigger_above_60_Male_count = trigger_above_60_Male_count + 1            \n",
    "            \n",
    "print('trigger_below_20_Female_count = ', trigger_below_20_Female_count)\n",
    "print('trigger_between_20_40_Female_count = ', trigger_between_20_40_Female_count)\n",
    "print('trigger_between_40_60_Female_count = ', trigger_between_40_60_Female_count)\n",
    "print('trigger_above_60_Female_count = ', trigger_above_60_Female_count)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Male_count = ', trigger_below_20_Male_count)\n",
    "print('trigger_between_20_40_Male_count = ', trigger_between_20_40_Male_count)\n",
    "print('trigger_between_40_60_Male_count = ', trigger_between_40_60_Male_count)\n",
    "print('trigger_above_60_Male_count = ', trigger_above_60_Male_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD_gender_female = data_no_trigger[data_no_trigger.Gender == 'Female']\n",
    "datapool_ESRD_gender_male = data_no_trigger[data_no_trigger.Gender == 'Male']\n",
    "\n",
    "\n",
    "datapool_ESRD_gender_female.patient_sk.unique().shape[0]\n",
    "datapool_ESRD_gender_male.patient_sk.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Races\n",
    "\n",
    "trigger_below_20_African_American_count = 0\n",
    "trigger_between_20_40_African_American_count = 0\n",
    "trigger_between_40_60_African_American_count = 0\n",
    "trigger_above_60_African_American_count = 0\n",
    "\n",
    "trigger_below_20_Native_American_count = 0\n",
    "trigger_between_20_40_Native_American_count = 0\n",
    "trigger_between_40_60_Native_American_count = 0\n",
    "trigger_above_60_Native_American_count = 0\n",
    "\n",
    "trigger_below_20_Asian_Pacific_Islander_count = 0\n",
    "trigger_between_20_40_Asian_Pacific_Islander_count = 0\n",
    "trigger_between_40_60_Asian_Pacific_Islander_count = 0\n",
    "trigger_above_60_Asian_Pacific_Islander_count = 0\n",
    "\n",
    "trigger_below_20_Hispanic_count = 0\n",
    "trigger_between_20_40_Hispanic_count = 0\n",
    "trigger_between_40_60_Hispanic_count = 0\n",
    "trigger_above_60_Hispanic_count = 0\n",
    "\n",
    "trigger_below_20_Biracial_count = 0\n",
    "trigger_between_20_40_Biracial_count = 0\n",
    "trigger_between_40_60_Biracial_count = 0\n",
    "trigger_above_60_Biracial_count = 0\n",
    "\n",
    "trigger_below_20_Caucasian_count = 0\n",
    "trigger_between_20_40_Caucasian_count = 0\n",
    "trigger_between_40_60_Caucasian_count = 0\n",
    "trigger_above_60_Caucasian_count = 0\n",
    "\n",
    "trigger_below_20_Mid_Eastern_Indian_count = 0\n",
    "trigger_between_20_40_Mid_Eastern_Indian_count = 0\n",
    "trigger_between_40_60_Mid_Eastern_Indian_count = 0\n",
    "trigger_above_60_Mid_Eastern_Indian_count = 0\n",
    "\n",
    "trigger_below_20_Unknown_count = 0\n",
    "trigger_between_20_40_Unknown_count = 0\n",
    "trigger_between_40_60_Unknown_count = 0\n",
    "trigger_above_60_Unknown_count = 0\n",
    "\n",
    "for patient_sk in count_list:\n",
    "    \n",
    "    if patient_sk in trigger_below_20:\n",
    "        if Races[count_list.index(patient_sk)] == 'African American':\n",
    "            trigger_below_20_African_American_count = trigger_below_20_African_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Native American':\n",
    "            trigger_below_20_Native_American_count = trigger_below_20_Native_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] in ['Asian', 'Asian/Pacific Islander', 'Pacific Islander'] :\n",
    "            trigger_below_20_Asian_Pacific_Islander_count = trigger_below_20_Asian_Pacific_Islander_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Hispanic':\n",
    "            trigger_below_20_Hispanic_count = trigger_below_20_Hispanic_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Mid Eastern Indian':\n",
    "            trigger_below_20_Mid_Eastern_Indian_count = trigger_below_20_Mid_Eastern_Indian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Caucasian':\n",
    "            trigger_below_20_Caucasian_count = trigger_below_20_Caucasian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] ==  'Biracial':\n",
    "            trigger_below_20_Biracial_count = trigger_below_20_Biracial_count + 1            \n",
    "        else:\n",
    "            trigger_below_20_Unknown_count = trigger_below_20_Unknown_count + 1    \n",
    "\n",
    "    if patient_sk in trigger_between_20_40:\n",
    "        if Races[count_list.index(patient_sk)] == 'African American':\n",
    "            trigger_between_20_40_African_American_count = trigger_between_20_40_African_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Native American':\n",
    "            trigger_between_20_40_Native_American_count = trigger_between_20_40_Native_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] in ['Asian', 'Asian/Pacific Islander', 'Pacific Islander'] :\n",
    "            trigger_between_20_40_Asian_Pacific_Islander_count = trigger_between_20_40_Asian_Pacific_Islander_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Hispanic':\n",
    "            trigger_between_20_40_Hispanic_count = trigger_between_20_40_Hispanic_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Mid Eastern Indian':\n",
    "            trigger_between_20_40_Mid_Eastern_Indian_count = trigger_between_20_40_Mid_Eastern_Indian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Caucasian':\n",
    "            trigger_between_20_40_Caucasian_count = trigger_between_20_40_Caucasian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] ==  'Biracial':\n",
    "            trigger_between_20_40_Biracial_count = trigger_between_20_40_Biracial_count + 1            \n",
    "        else:\n",
    "            trigger_between_20_40_Unknown_count = trigger_between_20_40_Unknown_count + 1  \n",
    "            \n",
    "    if patient_sk in trigger_between_40_60:\n",
    "        if Races[count_list.index(patient_sk)] == 'African American':\n",
    "            trigger_between_40_60_African_American_count = trigger_between_40_60_African_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Native American':\n",
    "            trigger_between_40_60_Native_American_count = trigger_between_40_60_Native_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] in ['Asian', 'Asian/Pacific Islander', 'Pacific Islander'] :\n",
    "            trigger_between_40_60_Asian_Pacific_Islander_count = trigger_between_40_60_Asian_Pacific_Islander_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Hispanic':\n",
    "            trigger_between_40_60_Hispanic_count = trigger_between_40_60_Hispanic_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Mid Eastern Indian':\n",
    "            trigger_between_40_60_Mid_Eastern_Indian_count = trigger_between_40_60_Mid_Eastern_Indian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Caucasian':\n",
    "            trigger_between_40_60_Caucasian_count = trigger_between_40_60_Caucasian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] ==  'Biracial':\n",
    "            trigger_between_40_60_Biracial_count = trigger_between_40_60_Biracial_count + 1            \n",
    "        else:\n",
    "            trigger_between_40_60_Unknown_count = trigger_between_40_60_Unknown_count + 1  \n",
    "            \n",
    "    if patient_sk in trigger_above_60:\n",
    "        if Races[count_list.index(patient_sk)] == 'African American':\n",
    "            trigger_above_60_African_American_count = trigger_above_60_African_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Native American':\n",
    "            trigger_above_60_Native_American_count = trigger_above_60_Native_American_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] in ['Asian', 'Asian/Pacific Islander', 'Pacific Islander'] :\n",
    "            trigger_above_60_Asian_Pacific_Islander_count = trigger_above_60_Asian_Pacific_Islander_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Hispanic':\n",
    "            trigger_above_60_Hispanic_count = trigger_above_60_Hispanic_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Mid Eastern Indian':\n",
    "            trigger_above_60_Mid_Eastern_Indian_count = trigger_above_60_Mid_Eastern_Indian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] == 'Caucasian':\n",
    "            trigger_above_60_Caucasian_count = trigger_above_60_Caucasian_count + 1\n",
    "        elif Races[count_list.index(patient_sk)] ==  'Biracial':\n",
    "            trigger_above_60_Biracial_count = trigger_above_60_Biracial_count + 1            \n",
    "        else:\n",
    "            trigger_above_60_Unknown_count = trigger_above_60_Unknown_count + 1    \n",
    "            \n",
    "\n",
    "print('trigger_below_20_African_American_count = ', trigger_below_20_African_American_count/456)\n",
    "print('trigger_between_20_40_African_American_count = ', trigger_between_20_40_African_American_count/962)\n",
    "print('trigger_between_40_60_African_American_count = ', trigger_between_40_60_African_American_count/2379)\n",
    "print('trigger_above_60_African_American_count = ', trigger_above_60_African_American_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Native_American_count = ', trigger_below_20_Native_American_count/456)\n",
    "print('trigger_between_20_40_Native_American_count = ', trigger_between_20_40_Native_American_count/962)\n",
    "print('trigger_between_40_60_Native_American_count = ', trigger_between_40_60_Native_American_count/2379)\n",
    "print('trigger_above_60_Native_American_count = ', trigger_above_60_Native_American_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Asian_Pacific_Islander_count = ', trigger_below_20_Asian_Pacific_Islander_count/456)\n",
    "print('trigger_between_20_40_Asian_Pacific_Islander_count = ', trigger_between_20_40_Asian_Pacific_Islander_count/962)\n",
    "print('trigger_between_40_60_Asian_Pacific_Islander_count = ', trigger_between_40_60_Asian_Pacific_Islander_count/2379)\n",
    "print('trigger_above_60_Asian_Pacific_Islander_count = ', trigger_above_60_Asian_Pacific_Islander_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Hispanic_count = ', trigger_below_20_Hispanic_count/456)\n",
    "print('trigger_between_20_40_Hispanic_count = ', trigger_between_20_40_Hispanic_count/962)\n",
    "print('trigger_between_40_60_Hispanic_count = ', trigger_between_40_60_Hispanic_count/2379)\n",
    "print('trigger_above_60_Hispanic_count = ', trigger_above_60_Hispanic_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Mid_Eastern_Indian_count = ', trigger_below_20_Mid_Eastern_Indian_count/456)\n",
    "print('trigger_between_20_40_Mid_Eastern_Indian_count = ', trigger_between_20_40_Mid_Eastern_Indian_count/962)\n",
    "print('trigger_between_40_60_Mid_Eastern_Indian_count = ', trigger_between_40_60_Mid_Eastern_Indian_count/2379)\n",
    "print('trigger_above_60_Mid_Eastern_Indian_count = ', trigger_above_60_Mid_Eastern_Indian_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Caucasian_count = ', trigger_below_20_Caucasian_count/456)\n",
    "print('trigger_between_20_40_Caucasian_count = ', trigger_between_20_40_Caucasian_count/962)\n",
    "print('trigger_between_40_60_Caucasian_count = ', trigger_between_40_60_Caucasian_count/2379)\n",
    "print('trigger_above_60_Caucasian_count = ', trigger_above_60_Caucasian_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Biracial_count = ', trigger_below_20_Biracial_count/456)\n",
    "print('trigger_between_20_40_Biracial_count = ', trigger_between_20_40_Biracial_count/962)\n",
    "print('trigger_between_40_60_Biracial_count = ', trigger_between_40_60_Biracial_count/2379)\n",
    "print('trigger_above_60_Biracial_count = ', trigger_above_60_Biracial_count/1124)\n",
    "print('\\n')\n",
    "print('trigger_below_20_Unknown_count = ', trigger_below_20_Unknown_count/456)\n",
    "print('trigger_between_20_40_Unknown_count = ', trigger_between_20_40_Unknown_count/962)\n",
    "print('trigger_between_40_60_Unknown_count = ', trigger_between_40_60_Unknown_count/2379)\n",
    "print('trigger_above_60_Unknown_count = ', trigger_above_60_Unknown_count/1124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD_race = datapool_ESRD.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "dataaa_ESRD = datapool_ESRD_race.reset_index()\n",
    "\n",
    "African_Americans = dataaa_ESRD[dataaa_ESRD['Race'] == 'African American']['Race']\n",
    "Native_Americans = dataaa_ESRD[dataaa_ESRD['Race'] == 'Native American']['Race']\n",
    "Asian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Asian']['Race']\n",
    "Pacific = dataaa_ESRD[dataaa_ESRD['Race'] == 'Pacific Islander']['Race']\n",
    "Hispanic = dataaa_ESRD[dataaa_ESRD['Race'] == 'Hispanic']['Race']\n",
    "Mid_Eastern_Indian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Mid Eastern Indian']['Race']\n",
    "Caucasian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Caucasian']['Race']\n",
    "Biracial = dataaa_ESRD[dataaa_ESRD['Race'] == 'Biracial']['Race']\n",
    "\n",
    "print('African_Americans', len(African_Americans), (len(African_Americans)/len(dataaa_ESRD))*100)\n",
    "print('Native_Americans', len(Native_Americans), (len(Native_Americans)/len(dataaa_ESRD))*100)\n",
    "print('Asian', len(Asian), (len(Asian)/len(dataaa_ESRD))*100)\n",
    "print('Pacific', len(Pacific), (len(Pacific)/len(dataaa_ESRD))*100)\n",
    "print('Hispanic', len(Hispanic), (len(Hispanic)/len(dataaa_ESRD))*100)\n",
    "print('Mid_Eastern_Indian', len(Mid_Eastern_Indian), (len(Mid_Eastern_Indian)/len(dataaa_ESRD))*100)\n",
    "print('Caucasian', len(Caucasian), (len(Caucasian)/len(dataaa_ESRD))*100)\n",
    "print('Biracial', len(Biracial), (len(Biracial)/len(dataaa_ESRD))*100)\n",
    "print(len(African_Americans) + len(Native_Americans) + len(Asian)+len(Pacific)+len(Hispanic)+len(Mid_Eastern_Indian)+len(Caucasian)+len(Biracial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD_race = data_no_trigger.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "dataaa_ESRD = datapool_ESRD_race.reset_index()\n",
    "\n",
    "African_Americans = dataaa_ESRD[dataaa_ESRD['Race'] == 'African American']['Race']\n",
    "Native_Americans = dataaa_ESRD[dataaa_ESRD['Race'] == 'Native American']['Race']\n",
    "Asian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Asian']['Race']\n",
    "Pacific = dataaa_ESRD[dataaa_ESRD['Race'] == 'Pacific Islander']['Race']\n",
    "Hispanic = dataaa_ESRD[dataaa_ESRD['Race'] == 'Hispanic']['Race']\n",
    "Mid_Eastern_Indian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Mid Eastern Indian']['Race']\n",
    "Caucasian = dataaa_ESRD[dataaa_ESRD['Race'] == 'Caucasian']['Race']\n",
    "Biracial = dataaa_ESRD[dataaa_ESRD['Race'] == 'Biracial']['Race']\n",
    "\n",
    "print('African_Americans', len(African_Americans), (len(African_Americans)/len(dataaa_ESRD))*100)\n",
    "print('Native_Americans', len(Native_Americans), (len(Native_Americans)/len(dataaa_ESRD))*100)\n",
    "print('Asian', len(Asian), (len(Asian)/len(dataaa_ESRD))*100)\n",
    "print('Pacific', len(Pacific), (len(Pacific)/len(dataaa_ESRD))*100)\n",
    "print('Hispanic', len(Hispanic), (len(Hispanic)/len(dataaa_ESRD))*100)\n",
    "print('Mid_Eastern_Indian', len(Mid_Eastern_Indian), (len(Mid_Eastern_Indian)/len(dataaa_ESRD))*100)\n",
    "print('Caucasian', len(Caucasian), (len(Caucasian)/len(dataaa_ESRD))*100)\n",
    "print('Biracial', len(Biracial), (len(Biracial)/len(dataaa_ESRD))*100)\n",
    "print(len(African_Americans) + len(Native_Americans) + len(Asian)+len(Pacific)+len(Hispanic)+len(Mid_Eastern_Indian)+len(Caucasian)+len(Biracial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'], errors='coerce')\n",
    "merged_dataset['Trigger_date'] = pd.to_datetime(merged_dataset['Trigger_date'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Nicotine_Tobacco_dependency = list(merged_dataset['Diagnosis_admission_date_Nicotine_Tobacco_dependency'])\n",
    "Trigger_date = list(merged_dataset['Trigger_date'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Nicotine_Tobacco_dependency)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Nicotine_Tobacco_dependency[i]):\n",
    "        Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Nicotine_Tobacco_dependency)):\n",
    "    if Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] <= Trigger_date[i] and Diagnosis_admission_date_Nicotine_Tobacco_dependency[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "print('Diagnosis_admission_date_Nicotine_Tobacco_dependency: ',count)\n",
    "\n",
    "# Now, the categorization\n",
    "print('trigger_below_20: ',len(list(set(count_list) & set(trigger_below_20))))\n",
    "print('trigger_between_20_40: ',len(list(set(count_list) & set(trigger_between_20_40))))\n",
    "print('trigger_between_40_60: ',len(list(set(count_list) & set(trigger_between_40_60))))\n",
    "print('trigger_above_60: ',len(list(set(count_list) & set(trigger_above_60))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, the Normal group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_control = pd.read_csv(\"Final_Normal_group_done_pandas.csv\")\n",
    "datapool_control = datapool_control.drop(columns=datapool_control.columns[0])\n",
    "\n",
    "datapool_control = datapool_control.drop(datapool_control.index[np.isinf(datapool_control.eGFR_EPI) == True], axis = 0)\n",
    "datapool_control = datapool_control.drop_duplicates()\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_control_dropped = datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_control_dropped = datapool_control_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_control = datapool_control.merge(datapool_control_dropped, on = 'patient_sk', how = 'inner')\n",
    "#Pulling out each patient's data \n",
    "#Also. sortinh the data by cSr lavel measurement data and reindexing it\n",
    "\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD_dates = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_dates = datapool_ESRD_dates.reset_index()\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dates, on = 'patient_sk', how='left')\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_x'] - datapool_ESRD['Date_y']\n",
    "datapool_ESRD = datapool_ESRD.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop('Date_y', axis = 1)\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "#Getting rid of Normal min eGFR < 60\n",
    "\n",
    "datapool_control_patients = datapool_control.groupby('patient_sk').agg({'eGFR_EPI': 'min'})\n",
    "datapool_control_patients = datapool_control_patients[datapool_control_patients['eGFR_EPI']>=60]\n",
    "datapool_control_patients = datapool_control_patients.reset_index()\n",
    "\n",
    "datapool_control = datapool_control_patients.merge(datapool_control, on = 'patient_sk', how = 'inner')\n",
    "datapool_control = datapool_control.rename({'eGFR_EPI_y':'eGFR_EPI'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('eGFR_EPI_x', axis = 1)\n",
    "\n",
    "patients_list_control_above_60 = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "\n",
    "patients_list_Normal = patients_list_control_above_60\n",
    "\n",
    "patients_list_Normal = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "len(patients_list_Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_list_Normal = datapool_control_patients.merge(datapool_Normal, on = 'patient_sk', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_control_age = datapool_control.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_control_age = datapool_control_age.reset_index()\n",
    "np.mean(datapool_control_age.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD_age = datapool_ESRD.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_ESRD_age = datapool_ESRD_age.reset_index()\n",
    "np.mean(datapool_ESRD_age.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_list_Normal_gender = patients_list_Normal[patients_list_Normal['Gender']<'Not Mapped']\n",
    "patients_list_Normal_gender = patients_list_Normal_gender.drop_duplicates('patient_sk')\n",
    "Genders_female = patients_list_Normal_gender[patients_list_Normal_gender['Gender'] == 'Female']['Gender']\n",
    "Genders_male = patients_list_Normal_gender[patients_list_Normal_gender['Gender'] == 'Male']['Gender']\n",
    "print('Genders_female', len(list(Genders_female)), (len(list(Genders_female))/len(patients_list_Normal_gender))*100)\n",
    "print('Genders_male', len(list(Genders_male)), (len(list(Genders_male))/len(patients_list_Normal_gender))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaa_Normal = patients_list_Normal.drop_duplicates('patient_sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaa_Normal['Race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaa_Normal = patients_list_Normal.drop_duplicates('patient_sk')dataaa_Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_Normal_race = datapool_control.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "dataaa_Normal = datapool_Normal_race.reset_index()\n",
    "\n",
    "African_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'African American']['Race']\n",
    "Native_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'Native American']['Race']\n",
    "Asian = dataaa_Normal[dataaa_Normal['Race'] == 'Asian']['Race']\n",
    "Pacific = dataaa_Normal[dataaa_Normal['Race'] == 'Pacific Islander']['Race']\n",
    "Hispanic = dataaa_Normal[dataaa_Normal['Race'] == 'Hispanic']['Race']\n",
    "Mid_Eastern_Indian = dataaa_Normal[dataaa_Normal['Race'] == 'Mid Eastern Indian']['Race']\n",
    "Caucasian = dataaa_Normal[dataaa_Normal['Race'] == 'Caucasian']['Race']\n",
    "Biracial = dataaa_Normal[dataaa_Normal['Race'] == 'Biracial']['Race']\n",
    "\n",
    "print('African_Americans', len(African_Americans), (len(African_Americans)/len(dataaa_Normal))*100)\n",
    "print('Native_Americans', len(Native_Americans), (len(Native_Americans)/len(dataaa_Normal))*100)\n",
    "print('Asian', len(Asian), (len(Asian)/len(dataaa_Normal))*100)\n",
    "print('Pacific', len(Pacific), (len(Pacific)/len(dataaa_Normal))*100)\n",
    "print('Hispanic', len(Hispanic), (len(Hispanic)/len(dataaa_Normal))*100)\n",
    "print('Mid_Eastern_Indian', len(Mid_Eastern_Indian), (len(Mid_Eastern_Indian)/len(dataaa_Normal))*100)\n",
    "print('Caucasian', len(Caucasian), (len(Caucasian)/len(dataaa_Normal))*100)\n",
    "print('Biracial', len(Biracial), (len(Biracial)/len(dataaa_Normal))*100)\n",
    "print(len(African_Americans) + len(Native_Americans) + len(Asian)+len(Pacific)+len(Hispanic)+len(Mid_Eastern_Indian)+len(Caucasian)+len(Biracial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_list_Normal_race = patients_list_Normal[patients_list_Normal['Race']<'Not Mapped']\n",
    "patients_list_Normal_race = patients_list_Normal_race.drop_duplicates('patient_sk')\n",
    "\n",
    "dataaa_Normal = patients_list_Normal_race\n",
    "\n",
    "African_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'African American']['Race']\n",
    "Native_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'Native American']['Race']\n",
    "Asian = dataaa_Normal[dataaa_Normal['Race'] == 'Asian']['Race']\n",
    "Pacific = dataaa_Normal[dataaa_Normal['Race'] == 'Pacific Islander']['Race']\n",
    "Hispanic = dataaa_Normal[dataaa_Normal['Race'] == 'Hispanic']['Race']\n",
    "Mid_Eastern_Indian = dataaa_Normal[dataaa_Normal['Race'] == 'Mid Eastern Indian']['Race']\n",
    "Caucasian = dataaa_Normal[dataaa_Normal['Race'] == 'Caucasian']['Race']\n",
    "Biracial = dataaa_Normal[dataaa_Normal['Race'] == 'Biracial']['Race']\n",
    "Other = dataaa_Normal[dataaa_Normal['Race'] == 'Other']['Race']\n",
    "\n",
    "print('African_Americans', len(African_Americans), (len(African_Americans)/len(dataaa_Normal))*100)\n",
    "print('Native_Americans', len(Native_Americans), (len(Native_Americans)/len(dataaa_Normal))*100)\n",
    "print('Asian', len(Asian), (len(Asian)/len(dataaa_Normal))*100)\n",
    "print('Pacific', len(Pacific), (len(Pacific)/len(dataaa_Normal))*100)\n",
    "print('Hispanic', len(Hispanic), (len(Hispanic)/len(dataaa_Normal))*100)\n",
    "print('Mid_Eastern_Indian', len(Mid_Eastern_Indian), (len(Mid_Eastern_Indian)/len(dataaa_Normal))*100)\n",
    "print('Caucasian', len(Caucasian), (len(Caucasian)/len(dataaa_Normal))*100)\n",
    "print('Biracial', len(Biracial), (len(Biracial)/len(dataaa_Normal))*100)\n",
    "print('Other', len(Other), (len(Other)/len(dataaa_Normal))*100)\n",
    "\n",
    "print(len(African_Americans) + len(Native_Americans) + len(Asian)+len(Pacific)+len(Hispanic)+len(Mid_Eastern_Indian)+len(Caucasian)+len(Biracial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_list_Normal_race = patients_list_Normal[patients_list_Normal['Race']>='Not Mapped']\n",
    "patients_list_Normal_race = patients_list_Normal_race.drop_duplicates('patient_sk')\n",
    "\n",
    "dataaa_Normal = patients_list_Normal_race\n",
    "\n",
    "African_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'African American']['Race']\n",
    "Native_Americans = dataaa_Normal[dataaa_Normal['Race'] == 'Native American']['Race']\n",
    "Asian = dataaa_Normal[dataaa_Normal['Race'] == 'Asian']['Race']\n",
    "Pacific = dataaa_Normal[dataaa_Normal['Race'] == 'Pacific Islander']['Race']\n",
    "Hispanic = dataaa_Normal[dataaa_Normal['Race'] == 'Hispanic']['Race']\n",
    "Mid_Eastern_Indian = dataaa_Normal[dataaa_Normal['Race'] == 'Mid Eastern Indian']['Race']\n",
    "Caucasian = dataaa_Normal[dataaa_Normal['Race'] == 'Caucasian']['Race']\n",
    "Biracial = dataaa_Normal[dataaa_Normal['Race'] == 'Biracial']['Race']\n",
    "Other = dataaa_Normal[dataaa_Normal['Race'] == 'Other']['Race']\n",
    "Unknown = dataaa_Normal[dataaa_Normal['Race'] == 'Unknown']['Race']\n",
    "\n",
    "print('African_Americans', len(African_Americans), (len(African_Americans)/len(dataaa_Normal))*100)\n",
    "print('Native_Americans', len(Native_Americans), (len(Native_Americans)/len(dataaa_Normal))*100)\n",
    "print('Asian', len(Asian), (len(Asian)/len(dataaa_Normal))*100)\n",
    "print('Pacific', len(Pacific), (len(Pacific)/len(dataaa_Normal))*100)\n",
    "print('Hispanic', len(Hispanic), (len(Hispanic)/len(dataaa_Normal))*100)\n",
    "print('Mid_Eastern_Indian', len(Mid_Eastern_Indian), (len(Mid_Eastern_Indian)/len(dataaa_Normal))*100)\n",
    "print('Caucasian', len(Caucasian), (len(Caucasian)/len(dataaa_Normal))*100)\n",
    "print('Biracial', len(Biracial), (len(Biracial)/len(dataaa_Normal))*100)\n",
    "print('Other', len(Other), (len(Other)/len(dataaa_Normal))*100)\n",
    "print('Unknown', len(Unknown), (len(Unknown)/len(dataaa_Normal))*100)\n",
    "print(len(African_Americans) + len(Native_Americans) + len(Asian)+len(Pacific)+len(Hispanic)+len(Mid_Eastern_Indian)+len(Caucasian)+len(Biracial))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For further information please contact rzz5164@psu.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
