{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the CUSUM algorithm to obtain qGFRv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * This code belongs to the paper \"Early Prediction of End Stage Kidney Disease Based on Cumulative Estimated Glomerular Filtration Rate Velocity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "import socket    \n",
    "hostname = socket.gethostname()    \n",
    "IPAddr = socket.gethostbyname(hostname)  \n",
    "\n",
    "#conf = SparkConf()\n",
    "conf = SparkConf().setAll([(\"spark.executor.instances\", '5'), ('spark.executor.memory', '8g'), ('spark.executor.cores', '5'), ('spark.driver.memory','3g'),('spark.sql.broadcastTimeout', '3000')])\n",
    "conf.setMaster('yarn')\n",
    "conf.setAppName('spark-yarn-2')\n",
    "#conf.set(\"spark.driver.host\", '10.42.7.162') #Change it accordingly based on your host ip \n",
    "#address. Open a terminal and use \"cat /etc/hosts\", the last line is the host ip and the host name.\n",
    "conf.set(\"spark.driver.host\", IPAddr)#Change it accordingly based on your host ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD = pd.read_csv('Final_ESRD_group_done_pandas.csv')\n",
    "datapool_ESRD = datapool_ESRD.drop(columns=datapool_ESRD.columns[0])\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "datapool_control = pd.read_csv(\"Final_Normal_group_done_pandas.csv\")\n",
    "datapool_control = datapool_control.drop(columns=datapool_control.columns[0])\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_ESRD_dropped = datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_ESRD_dropped = datapool_ESRD_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_control = datapool_control.drop(datapool_control.index[np.isinf(datapool_control.eGFR_EPI) == True], axis = 0)\n",
    "datapool_control = datapool_control.drop_duplicates()\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_control_dropped = datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_control_dropped = datapool_control_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_control = datapool_control.merge(datapool_control_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "#Pulling out each patient's data \n",
    "#Also. sortinh the data by cSr lavel measurement data and reindexing it\n",
    "\n",
    "patients_list_Normal = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!! SHOULD TURN TO TOTAL_SECONDS IN THE MIDST OF ALGORITHM\n",
    "\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control_dates = datapool_control.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_control_dates = datapool_control_dates.reset_index()\n",
    "datapool_control = datapool_control.merge(datapool_control_dates, on = 'patient_sk', how='left')\n",
    "datapool_control['Date_seconds'] = (datapool_control['Date_x'] - datapool_control['Date_y'])\n",
    "datapool_control = datapool_control.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('Date_y', axis = 1)\n",
    "datapool_control['Date_seconds'] = datapool_control['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD_dates = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_dates = datapool_ESRD_dates.reset_index()\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dates, on = 'patient_sk', how='left')\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_x'] - datapool_ESRD['Date_y']\n",
    "datapool_ESRD = datapool_ESRD.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop('Date_y', axis = 1)\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_seconds'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of Normal min eGFR < 60\n",
    "\n",
    "datapool_control_patients = datapool_control.groupby('patient_sk').agg({'eGFR_EPI': 'min'})\n",
    "#datapool_control_patients = datapool_control_patients[datapool_control_patients['eGFR_EPI']>=60]\n",
    "datapool_control_patients = datapool_control_patients.reset_index()\n",
    "\n",
    "datapool_control = datapool_control_patients.merge(datapool_control, on = 'patient_sk', how = 'inner')\n",
    "datapool_control = datapool_control.rename({'eGFR_EPI_y':'eGFR_EPI'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('eGFR_EPI_x', axis = 1)\n",
    "\n",
    "patients_list_control_above_60 = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "\n",
    "patients_list_Normal = patients_list_control_above_60\n",
    "\n",
    "\n",
    "\n",
    "#Getting rid of ESRD min eGFR < 60\n",
    "\n",
    "datapool_ESRD_patients = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_patients = datapool_ESRD_patients.reset_index()\n",
    "\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD.merge(datapool_ESRD_patients, on=['patient_sk', 'Date'], how ='inner')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR.drop_duplicates('patient_sk')\n",
    "#datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR[datapool_ESRD_patients_eGFR['eGFR_EPI']>=60]\n",
    "\n",
    "datapool_ESRD_new = datapool_ESRD.merge(datapool_ESRD_patients_eGFR['patient_sk'], on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_ESRD = datapool_ESRD_new\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datapool_control.patient_sk.unique().shape[0])\n",
    "print(datapool_ESRD.patient_sk.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool_ESRD[['patient_sk']].drop_duplicates().to_csv('kept_ESRD_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mu and sigma\n",
    "\n",
    "var_list = []\n",
    "n_list = []\n",
    "\n",
    "mu = np.mean(datapool_control['eGFR_EPI'])\n",
    "\n",
    "var_list = datapool_control.groupby('patient_sk').agg({'eGFR_EPI':'std'})\n",
    "var_list = list(var_list.eGFR_EPI)\n",
    "\n",
    "n_list =  datapool_control.groupby('patient_sk').agg({'patient_sk':'count'})\n",
    "n_list = list(n_list.patient_sk)\n",
    "#calculating the mean and variance of the Normal sample\n",
    "\n",
    "n_1 = list((n_list - np.ones(len(n_list))).astype('int'))\n",
    "numerator = np.multiply(n_1, np.power(var_list, 2))\n",
    "denominator = sum(n_list) - len(n_list)\n",
    "sigma = np.power(sum(numerator)/denominator,0.5)\n",
    "\n",
    "print(mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the Oscar goes to:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparametrs:\n",
    "\n",
    "V0 = 0\n",
    "w = 0.75\n",
    "T = -4\n",
    "a = 0.2\n",
    "\n",
    "\n",
    "## Zi:\n",
    "\n",
    "datapool_control['Zi'] = list((datapool_control.eGFR_EPI - mu)/sigma)\n",
    "datapool_ESRD['Zi'] = list((datapool_ESRD.eGFR_EPI - mu)/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND let us start palying with Zi and Vi :) AND THE SLOPES AS WELL\n",
    "from numba import jit\n",
    "@jit(nopython=True)\n",
    "\n",
    "def Vi_creator(Zi, patient_sk):\n",
    "    Vi = np.zeros(Zi.shape)\n",
    "    Vi[0] = V0\n",
    "\n",
    "    for i in range(1, Vi.shape[0]):\n",
    "        if patient_sk[i] == patient_sk[i-1]:\n",
    "            Vi[i] = (min(0.0, Zi[i] + w + Vi[i-1]))\n",
    "        else:\n",
    "            Vi[i] = V0\n",
    "            \n",
    "    return Vi\n",
    "\n",
    "datapool_control['Vi'] = Vi_creator(datapool_control['Zi'].values, datapool_control['patient_sk'].values)\n",
    "datapool_ESRD['Vi'] = Vi_creator(datapool_ESRD['Zi'].values, datapool_ESRD['patient_sk'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we go:\n",
    "\n",
    "Inst_slope_initial = 0.0\n",
    "Smooth_slope_initial = 0.0\n",
    "\n",
    "@jit(nopython=True)\n",
    "def Slope_creator(Vi, patient_sk, Date_seconds, eGFR_EPI):\n",
    "    Inst_slope = np.zeros(Vi.shape)\n",
    "    Smooth_slope = np.zeros(Vi.shape)\n",
    "    \n",
    "    Inst_slope[0] = Inst_slope_initial\n",
    "    Smooth_slope[0] = Smooth_slope_initial\n",
    "\n",
    "    for i in range(1, Vi.shape[0]):\n",
    "        if patient_sk[i] == patient_sk[i-1]:\n",
    "            if Vi[i-1] == 0.0 :\n",
    "                if Date_seconds[i] - Date_seconds[i-1] != 0:\n",
    "                    Inst_slope[i] = min(0.0, (eGFR_EPI[i] - mu)/((Date_seconds[i] - Date_seconds[i-1])/86400))\n",
    "                else:\n",
    "                    Inst_slope[i] = 0.0\n",
    "            else:\n",
    "                if Date_seconds[i] - Date_seconds[i-1] != 0:\n",
    "                    Inst_slope[i] = min(0.0, (eGFR_EPI[i] - eGFR_EPI[i-1])/((Date_seconds[i] - Date_seconds[i-1])/86400))\n",
    "                else:\n",
    "                    Inst_slope[i] = 0.0\n",
    "            if Date_seconds[i] - Date_seconds[i-1] != 0:\n",
    "                Smooth_slope[i] = (1-a) * Smooth_slope[i-1] + a * (min(0.0, (eGFR_EPI[i] - eGFR_EPI[i-1])/((Date_seconds[i] - Date_seconds[i-1])/86400)))\n",
    "            else:\n",
    "                Smooth_slope[i] = Smooth_slope[i-1]\n",
    "        else:\n",
    "            Inst_slope[i] = Inst_slope_initial\n",
    "            Smooth_slope[i] = Smooth_slope_initial\n",
    "            \n",
    "    return [Inst_slope, Smooth_slope]\n",
    "\n",
    "[datapool_control['Inst_slope'],datapool_control['Smooth_slope']] = Slope_creator(datapool_control['Vi'].values, datapool_control['patient_sk'].values, datapool_control['Date_seconds'].values, datapool_control['eGFR_EPI'].values)\n",
    "[datapool_ESRD['Inst_slope'], datapool_ESRD['Smooth_slope']] = Slope_creator(datapool_ESRD['Vi'].values, datapool_ESRD['patient_sk'].values, datapool_ESRD['Date_seconds'].values, datapool_ESRD['eGFR_EPI'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the result trigger date and eGFR tables\n",
    "\n",
    "patients_control_trigger = datapool_control[datapool_control['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "patients_control_trigger = patients_control_trigger.reset_index()\n",
    "patients_control_trigger = patients_control_trigger.merge(datapool_control[['patient_sk', 'eGFR_EPI', 'Date', 'Inst_slope', 'Smooth_slope']], on=['patient_sk'], how='inner')\n",
    "patients_control_trigger = patients_control_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "patients_control_trigger = patients_control_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "patients_control_trigger = patients_control_trigger[patients_control_trigger.Trigger_date == patients_control_trigger.Date]\n",
    "patients_control_trigger['New_label'] = list(np.ones(patients_control_trigger.patient_sk.shape[0]))\n",
    "\n",
    "patients_ESRD_trigger = datapool_ESRD[datapool_ESRD['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.reset_index()\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.merge(datapool_ESRD[['patient_sk', 'eGFR_EPI', 'Date', 'Inst_slope', 'Smooth_slope']], on=['patient_sk'], how='inner')\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "patients_ESRD_trigger = patients_ESRD_trigger[patients_ESRD_trigger.Trigger_date == patients_ESRD_trigger.Date]\n",
    "patients_ESRD_trigger['New_label'] = list(np.ones(patients_ESRD_trigger.patient_sk.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling and finishing :)\n",
    "\n",
    "patients_Normal_labeled = pd.DataFrame({'patient_sk' : list(datapool_control.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_control.patient_sk.unique()))))}) \n",
    "\n",
    "patients_Normal_labeled =  patients_Normal_labeled.merge(patients_control_trigger, on='patient_sk', how='left')\n",
    "patients_Normal_labeled = patients_Normal_labeled.drop_duplicates('patient_sk')\n",
    "patients_Normal_labeled = patients_Normal_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "patients_ESRD_labeled = pd.DataFrame({'patient_sk' : list(datapool_ESRD.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_ESRD.patient_sk.unique()))))}) \n",
    "\n",
    "patients_ESRD_labeled =  patients_ESRD_labeled.merge(patients_ESRD_trigger, on='patient_sk', how='left')\n",
    "patients_ESRD_labeled = patients_ESRD_labeled.drop_duplicates('patient_sk')\n",
    "patients_ESRD_labeled = patients_ESRD_labeled.drop('Date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy = true(positive and negative)/total population\n",
    "# ESRD NaN = 0.0\n",
    "# Normal NaN = 0.0\n",
    "\n",
    "#RIGHT detection in ESRD:\n",
    "numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "#WRONG detection in Normal\n",
    "numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "#Sensetivity\n",
    "tp = numbet_of_ones_ESRD\n",
    "fn = total_ESRD - numbet_of_ones_ESRD\n",
    "Sensetivity = tp/(tp+fn)\n",
    "\n",
    "#Specificity\n",
    "tn = total_Normal - numbet_of_ones_Normal\n",
    "fp = numbet_of_ones_Normal\n",
    "Specificity = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "sns.distplot(patients_ESRD_labeled['eGFR_EPI'], bins=25, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"eGFR-EPI at the trigger point\", ylabel = \"Frequency\")\n",
    "\n",
    "\n",
    "plt.savefig('plot1.jpg', orientation=\"landscape\",\n",
    "           dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "sns.distplot(patients_ESRD_labeled['eGFR_EPI'], bins=25, color=\"darkslategray\", ax=ax)\n",
    "ax.set(xlabel=\"eGFR-EPI at the trigger point\", ylabel = \"Probability\")\n",
    "\n",
    "\n",
    "plt.savefig('plot2.jpg', orientation=\"landscape\",\n",
    "           dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "merged_dataset = patients_ESRD_labeled\n",
    "\n",
    "new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "merged_dataset = merged_dataset.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "lislis_ESRD = (merged_dataset['Diagnosis_admission_date_ESRD'] - merged_dataset['Trigger_date'])\n",
    "\n",
    "merged_dataset['time_to_event_ESRD'] = lislis_ESRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"white\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients\", ylabel = \"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"whitegrid\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax ,  kde_kws = {'cumulative': True})\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients - Cumulative plot \", ylabel = \"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    if i.total_seconds() >= 0 | pd.isnull(i) == False:\n",
    "        y.append(i.total_seconds()/(2.628e+6))\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs\", ylabel = \"Frequency\")\n",
    "ax.set(xlim=(250, 0))\n",
    "ax.invert_xaxis()\n",
    "plt.savefig('plot3.jpg', orientation=\"landscape\",\n",
    "           dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    if i.total_seconds() >= 0 | pd.isnull(i) == False:\n",
    "        y.append(i.total_seconds()/(2.628e+6))\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax)\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs\", ylabel = \"Probability\")\n",
    "ax.set(xlim=(250, 0))\n",
    "ax.invert_xaxis()\n",
    "plt.savefig('plot3.jpg', orientation=\"landscape\",\n",
    "           dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"whitegrid\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax ,  kde_kws = {'cumulative': True})\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients - Cumulative plot \", ylabel = \"\")\n",
    "\n",
    "ax.set(ylim=(0.23, 1))\n",
    "ax.set(xlim=(0, 250))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For further information please contact rzz5164@psu.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
