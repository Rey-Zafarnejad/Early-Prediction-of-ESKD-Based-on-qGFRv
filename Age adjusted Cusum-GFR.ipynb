{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the CUSUM algorithm to obtain qGFRv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### * This code belongs to the paper \"Using CUSUM in real time to signal clinically relevant decreases in estimated glomerular filtration rate\"\n",
    "##### To cite: Zafarnejad, R., Dumbauld, S., Dumbauld, D. et al. Using CUSUM in real time to signal clinically relevant decreases in estimated glomerular filtration rate. BMC Nephrol 23, 287 (2022). https://doi.org/10.1186/s12882-022-02910-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "import socket    \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapool_ESRD = pd.read_csv('Final_ESRD_group_done_pandas.csv')\n",
    "datapool_ESRD = datapool_ESRD.drop(columns=datapool_ESRD.columns[0])\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "datapool_control = pd.read_csv(\"Final_Normal_group_done_pandas.csv\")\n",
    "datapool_control = datapool_control.drop(columns=datapool_control.columns[0])\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_ESRD_dropped = datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_ESRD_dropped = datapool_ESRD_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_control = datapool_control.drop(datapool_control.index[np.isinf(datapool_control.eGFR_EPI) == True], axis = 0)\n",
    "datapool_control = datapool_control.drop_duplicates()\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_control_dropped = datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_control_dropped = datapool_control_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_control = datapool_control.merge(datapool_control_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "#Pulling out each patient's data \n",
    "#Also. sortinh the data by cSr lavel measurement data and reindexing it\n",
    "\n",
    "patients_list_Normal = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!!! SHOULD TURN TO TOTAL_SECONDS IN THE MIDST OF ALGORITHM\n",
    "\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control_dates = datapool_control.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_control_dates = datapool_control_dates.reset_index()\n",
    "datapool_control = datapool_control.merge(datapool_control_dates, on = 'patient_sk', how='left')\n",
    "datapool_control['Date_seconds'] = (datapool_control['Date_x'] - datapool_control['Date_y'])\n",
    "datapool_control = datapool_control.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('Date_y', axis = 1)\n",
    "datapool_control['Date_seconds'] = datapool_control['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD_dates = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_dates = datapool_ESRD_dates.reset_index()\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dates, on = 'patient_sk', how='left')\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_x'] - datapool_ESRD['Date_y']\n",
    "datapool_ESRD = datapool_ESRD.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop('Date_y', axis = 1)\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_seconds'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting rid of Normal min eGFR < 60\n",
    "\n",
    "datapool_control_patients = datapool_control.groupby('patient_sk').agg({'eGFR_EPI': 'min'})\n",
    "datapool_control_patients = datapool_control_patients[datapool_control_patients['eGFR_EPI']>=60]\n",
    "datapool_control_patients = datapool_control_patients.reset_index()\n",
    "\n",
    "datapool_control = datapool_control_patients.merge(datapool_control, on = 'patient_sk', how = 'inner')\n",
    "datapool_control = datapool_control.rename({'eGFR_EPI_y':'eGFR_EPI'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('eGFR_EPI_x', axis = 1)\n",
    "\n",
    "patients_list_control_above_60 = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "\n",
    "patients_list_Normal = patients_list_control_above_60\n",
    "\n",
    "\n",
    "\n",
    "#Getting rid of ESRD min eGFR < 60\n",
    "\n",
    "datapool_ESRD_patients = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_patients = datapool_ESRD_patients.reset_index()\n",
    "\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD.merge(datapool_ESRD_patients, on=['patient_sk', 'Date'], how ='inner')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR.drop_duplicates('patient_sk')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR[datapool_ESRD_patients_eGFR['eGFR_EPI']>=60]\n",
    "\n",
    "datapool_ESRD_new = datapool_ESRD.merge(datapool_ESRD_patients_eGFR['patient_sk'], on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_ESRD = datapool_ESRD_new\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OLD formula\n",
    "\n",
    "datapool_ESRD_intact = datapool_ESRD.copy()\n",
    "datapool_ESRD['k'] = 1\n",
    "datapool_ESRD['a'] = 1\n",
    "datapool_ESRD['1'] = 1\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'k'] = 0.7\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female','a'] = -0.329\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Male','k'] = 0.9\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Male','a'] = -0.411\n",
    "\n",
    "datapool_ESRD['sCr/k'] = datapool_ESRD['new_sCr']/datapool_ESRD['k']\n",
    "\n",
    "datapool_ESRD.loc[datapool_ESRD['Race'] == 'African American', 'newly_calculated_eGFR_old'] = 141 * datapool_ESRD[['sCr/k', '1']].min(axis=1)**datapool_ESRD['a'] * datapool_ESRD[['sCr/k', '1']].max(axis=1) ** (-1.209) * 0.993 ** datapool_ESRD['Age'] * 1.159\n",
    "datapool_ESRD.loc[datapool_ESRD['Race'] != 'African American', 'newly_calculated_eGFR_old'] = 141 * datapool_ESRD[['sCr/k', '1']].min(axis=1)**datapool_ESRD['a'] * datapool_ESRD[['sCr/k', '1']].max(axis=1) ** (-1.209) * 0.993 ** datapool_ESRD['Age']\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'newly_calculated_eGFR_old'] = datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'newly_calculated_eGFR_old'] * 1.018\n",
    "\n",
    "datapool_ESRD = datapool_ESRD.drop(['k', 'a', '1', 'sCr/k'], axis = 1)\n",
    "\n",
    "\n",
    "datapool_control_intact = datapool_control.copy()\n",
    "datapool_control['k'] = 1\n",
    "datapool_control['a'] = 1\n",
    "datapool_control['1'] = 1\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female', 'k'] = 0.7\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female','a'] = -0.329\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Male','k'] = 0.9\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Male','a'] = -0.411\n",
    "\n",
    "datapool_control['sCr/k'] = datapool_control['new_sCr']/datapool_control['k']\n",
    "datapool_control\n",
    "datapool_control.loc[datapool_control['Race'] == 'African American', 'newly_calculated_eGFR_old'] = 141 * datapool_control[['sCr/k', '1']].min(axis=1)**datapool_control['a'] * datapool_control[['sCr/k', '1']].max(axis=1) ** (-1.209) * 0.993 ** datapool_control['Age'] * 1.159\n",
    "datapool_control.loc[datapool_control['Race'] != 'African American', 'newly_calculated_eGFR_old'] = 141 * datapool_control[['sCr/k', '1']].min(axis=1)**datapool_control['a'] * datapool_control[['sCr/k', '1']].max(axis=1) ** (-1.209) * 0.993 ** datapool_control['Age']\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female', 'newly_calculated_eGFR_old'] = datapool_control.loc[datapool_control['Gender'] == 'Female', 'newly_calculated_eGFR_old'] * 1.018\n",
    "\n",
    "datapool_control = datapool_control.drop(['k', 'a', '1', 'sCr/k'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New 2022 formula\n",
    "\n",
    "datapool_ESRD_intact = datapool_ESRD.copy()\n",
    "datapool_ESRD['k'] = 1\n",
    "datapool_ESRD['a'] = 1\n",
    "datapool_ESRD['1'] = 1\n",
    "datapool_control['newly_calculated_eGFR_new']  = 1\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'k'] = 0.7\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female','a'] = -0.241\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Male','k'] = 0.9\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Male','a'] = -0.302\n",
    "\n",
    "datapool_ESRD['sCr/k'] = datapool_ESRD['new_sCr']/datapool_ESRD['k']\n",
    "datapool_ESRD['newly_calculated_eGFR_new'] = 142 * datapool_ESRD[['sCr/k', '1']].min(axis=1)**datapool_ESRD['a'] * datapool_ESRD[['sCr/k', '1']].max(axis=1) ** (-1.2) * 0.9938 ** datapool_ESRD['Age']\n",
    "datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'newly_calculated_eGFR_new'] = datapool_ESRD.loc[datapool_ESRD['Gender'] == 'Female', 'newly_calculated_eGFR_new'] * 1.012\n",
    "\n",
    "datapool_ESRD = datapool_ESRD.drop(['k', 'a', '1', 'sCr/k'], axis = 1)\n",
    "\n",
    "\n",
    "datapool_control_intact = datapool_control.copy()\n",
    "datapool_control['k'] = 1\n",
    "datapool_control['a'] = 1\n",
    "datapool_control['1'] = 1\n",
    "datapool_control['newly_calculated_eGFR_new']  = 1\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female', 'k'] = 0.7\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female','a'] = -0.241\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Male','k'] = 0.9\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Male','a'] = -0.302\n",
    "\n",
    "datapool_control['sCr/k'] = datapool_control['new_sCr']/datapool_control['k']\n",
    "datapool_control\n",
    "datapool_control['newly_calculated_eGFR_new'] = 142 * datapool_control[['sCr/k', '1']].min(axis=1)**datapool_control['a'] * datapool_control[['sCr/k', '1']].max(axis=1) ** (-1.2) * 0.9938 ** datapool_control['Age']\n",
    "datapool_control.loc[datapool_control['Gender'] == 'Female', 'newly_calculated_eGFR_new'] = datapool_control.loc[datapool_control['Gender'] == 'Female', 'newly_calculated_eGFR_new'] * 1.012\n",
    "\n",
    "datapool_control = datapool_control.drop(['k', 'a', '1', 'sCr/k'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapool_control = datapool_control.drop(['eGFR_EPI', 'newly_calculated_eGFR_old'], axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop(['eGFR_EPI', 'newly_calculated_eGFR_old'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.mean(datapool_control[(datapool_control['Age'] < 30)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))\n",
    "print(np.mean(datapool_control[(datapool_control['Age'] >= 30) & (datapool_control['Age'] < 40)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))\n",
    "print(np.mean(datapool_control[(datapool_control['Age'] >= 40) & (datapool_control['Age'] < 50)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))\n",
    "print(np.mean(datapool_control[(datapool_control['Age'] >= 50) & (datapool_control['Age'] < 60)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))\n",
    "print(np.mean(datapool_control[(datapool_control['Age'] >= 60) & (datapool_control['Age'] < 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))\n",
    "print(np.mean(datapool_control[(datapool_control['Age'] >= 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mu and sigma\n",
    "\n",
    "var_list = []\n",
    "n_list = []\n",
    "\n",
    "# _________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "# finiding the inital age:\n",
    "control_age_initial_df = datapool_control.groupby('patient_sk').agg({'Age' : 'min'}).rename(columns = {'Age' : 'initial_age'})\n",
    "datapool_control = datapool_control.join(control_age_initial_df, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "ESRD_age_initial_df = datapool_ESRD.groupby('patient_sk').agg({'Age' : 'min'}).rename(columns = {'Age' : 'initial_age'})\n",
    "datapool_ESRD = datapool_ESRD.join(ESRD_age_initial_df, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "# ____________________________________ Starting point : from CERNER  ____________________________________\n",
    "# finsing the right eGFR bin:\n",
    "datapool_control['starting_mu'] = 0\n",
    "datapool_control.loc[datapool_control['initial_age'] < 30, 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] < 30)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_control.loc[(datapool_control['initial_age'] >= 30) & (datapool_control['initial_age'] < 40), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 30) & (datapool_control['Age'] < 40)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_control.loc[(datapool_control['initial_age'] >= 40) & (datapool_control['initial_age'] < 50), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 40) & (datapool_control['Age'] < 50)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_control.loc[(datapool_control['initial_age'] >= 50) & (datapool_control['initial_age'] < 60), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 50) & (datapool_control['Age'] < 60)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_control.loc[(datapool_control['initial_age'] >= 60) & (datapool_control['initial_age'] < 70), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 60) & (datapool_control['Age'] < 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_control.loc[datapool_control['initial_age'] > 70, 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] > 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "\n",
    "datapool_ESRD['starting_mu'] = 0\n",
    "datapool_ESRD.loc[datapool_ESRD['initial_age'] < 30, 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] < 30)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_ESRD.loc[(datapool_ESRD['initial_age'] >= 30) & (datapool_ESRD['initial_age'] < 40), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 30) & (datapool_control['Age'] < 40)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_ESRD.loc[(datapool_ESRD['initial_age'] >= 40) & (datapool_ESRD['initial_age'] < 50), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 40) & (datapool_control['Age'] < 50)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_ESRD.loc[(datapool_ESRD['initial_age'] >= 50) & (datapool_ESRD['initial_age'] < 60), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 50) & (datapool_control['Age'] < 60)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_ESRD.loc[(datapool_ESRD['initial_age'] >= 60) & (datapool_ESRD['initial_age'] < 70), 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] >= 60) & (datapool_control['Age'] < 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "datapool_ESRD.loc[datapool_ESRD['initial_age'] > 70, 'starting_mu'] = np.mean(datapool_control[(datapool_control['Age'] > 70)].groupby('patient_sk').agg({'newly_calculated_eGFR_new' : 'mean'}).reset_index()['newly_calculated_eGFR_new'])\n",
    "\n",
    "\n",
    "# _________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "var_list = datapool_control.groupby('patient_sk').agg({'newly_calculated_eGFR_new':'std'})\n",
    "var_list = list(var_list.newly_calculated_eGFR_new)\n",
    "\n",
    "n_list =  datapool_control.groupby('patient_sk').agg({'patient_sk':'count'})\n",
    "n_list = list(n_list.patient_sk)\n",
    "#calculating the mean and variance of the Normal sample\n",
    "\n",
    "n_1 = list((n_list - np.ones(len(n_list))).astype('int'))\n",
    "numerator = np.multiply(n_1, np.power(var_list, 2))\n",
    "denominator = sum(n_list) - len(n_list)\n",
    "sigma = np.power(sum(numerator)/denominator,0.5)\n",
    "\n",
    "print('sigma: ', sigma)\n",
    "\n",
    "\n",
    "#Hyperparametrs:\n",
    "\n",
    "V0 = 0\n",
    "w = 0.75\n",
    "T = -4\n",
    "\n",
    "\n",
    "## AND let us start palying with Zi and Vi\n",
    "from numba import jit\n",
    "@jit(nopython=True)\n",
    "\n",
    "def Vi_creator(newly_calculated_eGFR_new, starting_mu, patient_sk, Age):\n",
    "    Zi = np.zeros(newly_calculated_eGFR_new.shape)\n",
    "    Zi[0] = 0\n",
    "    \n",
    "    for i in range(1, Zi.shape[0]):\n",
    "        if patient_sk[i] == patient_sk[i-1]:\n",
    "            delta_age = Age[i] - Age[i-1]\n",
    "            Zi[i] = (newly_calculated_eGFR_new[i] - (starting_mu[i] - 0.81 * (delta_age)))/sigma\n",
    "        else:\n",
    "            Zi[i] = 0\n",
    "            \n",
    "    \n",
    "    Vi = np.zeros(Zi.shape)\n",
    "    Vi[0] = V0\n",
    "\n",
    "    for i in range(1, Vi.shape[0]):\n",
    "        if patient_sk[i] == patient_sk[i-1]:\n",
    "            Vi[i] = (min(0.0, Zi[i] + w + Vi[i-1]))\n",
    "        else:\n",
    "            Vi[i] = V0\n",
    "            \n",
    "    return Vi\n",
    "\n",
    "datapool_control['Vi'] = Vi_creator(datapool_control['newly_calculated_eGFR_new'].values, datapool_control['starting_mu'].values, datapool_control['patient_sk'].values, datapool_control['Age'].values)\n",
    "datapool_ESRD['Vi'] = Vi_creator(datapool_ESRD['newly_calculated_eGFR_new'].values, datapool_ESRD['starting_mu'].values, datapool_ESRD['patient_sk'].values, datapool_ESRD['Age'].values)\n",
    "\n",
    "\n",
    "\n",
    "# Making up the result trigger date and eGFR tables\n",
    "\n",
    "patients_control_trigger = datapool_control[datapool_control['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "patients_control_trigger = patients_control_trigger.reset_index()\n",
    "patients_control_trigger = patients_control_trigger.merge(datapool_control[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "patients_control_trigger = patients_control_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "patients_control_trigger = patients_control_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "patients_control_trigger = patients_control_trigger[patients_control_trigger.Trigger_date == patients_control_trigger.Date]\n",
    "patients_control_trigger['New_label'] = list(np.ones(patients_control_trigger.patient_sk.shape[0]))\n",
    "\n",
    "patients_ESRD_trigger = datapool_ESRD[datapool_ESRD['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.reset_index()\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.merge(datapool_ESRD[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "patients_ESRD_trigger = patients_ESRD_trigger[patients_ESRD_trigger.Trigger_date == patients_ESRD_trigger.Date]\n",
    "patients_ESRD_trigger['New_label'] = list(np.ones(patients_ESRD_trigger.patient_sk.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "#Labeling and finishing :)\n",
    "\n",
    "patients_Normal_labeled = pd.DataFrame({'patient_sk' : list(datapool_control.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_control.patient_sk.unique()))))}) \n",
    "\n",
    "patients_Normal_labeled =  patients_Normal_labeled.merge(patients_control_trigger, on='patient_sk', how='left')\n",
    "patients_Normal_labeled = patients_Normal_labeled.drop_duplicates('patient_sk')\n",
    "patients_Normal_labeled = patients_Normal_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "patients_ESRD_labeled = pd.DataFrame({'patient_sk' : list(datapool_ESRD.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_ESRD.patient_sk.unique()))))}) \n",
    "\n",
    "patients_ESRD_labeled =  patients_ESRD_labeled.merge(patients_ESRD_trigger, on='patient_sk', how='left')\n",
    "patients_ESRD_labeled = patients_ESRD_labeled.drop_duplicates('patient_sk')\n",
    "patients_ESRD_labeled = patients_ESRD_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "#Accuracy = true(positive and negative)/total population\n",
    "# ESRD NaN = 0.0\n",
    "# Normal NaN = 0.0\n",
    "\n",
    "#RIGHT detection in ESRD:\n",
    "numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "#WRONG detection in Normal\n",
    "numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "#Sensetivity\n",
    "tp = numbet_of_ones_ESRD\n",
    "fn = total_ESRD - numbet_of_ones_ESRD\n",
    "Sensetivity = tp/(tp+fn)\n",
    "\n",
    "#Specificity\n",
    "tn = total_Normal - numbet_of_ones_Normal\n",
    "fp = numbet_of_ones_Normal\n",
    "Specificity = tn/(tn+fp)\n",
    "\n",
    "\n",
    "\n",
    "#Accuracy = true(positive and negative)/total population\n",
    "# ESRD NaN = 0.0\n",
    "# Normal NaN = 0.0\n",
    "\n",
    "#RIGHT detection in ESRD:\n",
    "numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "#WRONG detection in Normal\n",
    "numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "#Sensetivity\n",
    "tp = numbet_of_ones_ESRD\n",
    "fn = total_ESRD - numbet_of_ones_ESRD\n",
    "Sensetivity = tp/(tp+fn)\n",
    "\n",
    "#Specificity\n",
    "tn = total_Normal - numbet_of_ones_Normal\n",
    "fp = numbet_of_ones_Normal\n",
    "Specificity = tn/(tn+fp)\n",
    "\n",
    "\n",
    "print('Sensetivity: ', Sensetivity)\n",
    "print('Specificity: ', Specificity)\n",
    "print('Accuracy: ', Accuracy)\n",
    "print(patients_Normal_labeled[(patients_Normal_labeled['New_label'] == 1) & (patients_Normal_labeled['newly_calculated_eGFR_new'] > 60)].shape[0]/patients_Normal_labeled.shape[0], 'triggered > 60 - Normal')\n",
    "print(patients_ESRD_labeled[(patients_ESRD_labeled['New_label'] == 1) & (patients_ESRD_labeled['newly_calculated_eGFR_new'] > 60)].shape[0]/patients_ESRD_labeled.shape[0], 'triggered > 60 - ESKD')\n",
    "numbet_of_ones_ESRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnosis_data = pd.read_csv(\"DIAGNOSIS_2.csv\")\n",
    "\n",
    "patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "merged_dataset = patients_ESRD_labeled\n",
    "\n",
    "new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "merged_dataset = merged_dataset.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "merged_dataset = merged_dataset.merge(diagnosis_data, on = 'patient_sk' , how = 'inner')\n",
    "merged_dataset = merged_dataset.rename(columns={'eGFR_EPI': 'Trigger_eGFR'})\n",
    "\n",
    "\n",
    "lislis_ESRD = (merged_dataset['Diagnosis_admission_date_ESRD'] - merged_dataset['Trigger_date'])\n",
    "\n",
    "merged_dataset['time_to_event_ESRD'] = lislis_ESRD\n",
    "\n",
    "#Age ESRD\n",
    "\n",
    "datapool_ESRD_age = datapool_ESRD.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_ESRD_age = datapool_ESRD_age.reset_index()\n",
    "\n",
    "patient_ESRD_working_age = datapool_ESRD_age[datapool_ESRD_age.Age < 65].drop('Age', axis =1)\n",
    "datapool_ESRD_working_age = datapool_ESRD.merge(patient_ESRD_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_none_working_age = datapool_ESRD_age[datapool_ESRD_age.Age >= 65].drop('Age', axis =1)\n",
    "datapool_ESRD_none_working_age = datapool_ESRD.merge(patient_ESRD_none_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Age Normal\n",
    "\n",
    "datapool_control_age = datapool_control.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_control_age = datapool_control_age.reset_index()\n",
    "\n",
    "patient_control_working_age = datapool_control_age[datapool_control_age.Age < 65].drop('Age', axis =1)\n",
    "datapool_control_working_age = datapool_control.merge(patient_control_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_none_working_age = datapool_control_age[datapool_control_age.Age >= 65].drop('Age', axis =1)\n",
    "datapool_control_none_working_age = datapool_control.merge(patient_control_none_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Gender ESRD\n",
    "\n",
    "datapool_ESRD_gender = datapool_ESRD[(datapool_ESRD.Gender == 'Female') | (datapool_ESRD.Gender == 'Male')]\n",
    "datapool_ESRD_gender = datapool_ESRD_gender.groupby('patient_sk').agg({'Gender': lambda x: x.iloc[0]}) #getting the first non_NONE gender reported (sex essentially)\n",
    "datapool_ESRD_gender = datapool_ESRD_gender.reset_index()\n",
    "\n",
    "patients_ESRD_gender_female = datapool_ESRD_gender[datapool_ESRD_gender.Gender == 'Female'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "patients_ESRD_gender_male = datapool_ESRD_gender[datapool_ESRD_gender.Gender == 'Male'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "\n",
    "datapool_ESRD_Female = datapool_ESRD.merge(patients_ESRD_gender_female, on = ['patient_sk'], how = 'inner')\n",
    "datapool_ESRD_Male = datapool_ESRD.merge(patients_ESRD_gender_male, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Gender Normal\n",
    "\n",
    "datapool_control_gender = datapool_control[(datapool_control.Gender == 'Female') | (datapool_control.Gender == 'Male')]\n",
    "datapool_control_gender = datapool_control_gender.groupby('patient_sk').agg({'Gender': lambda x: x.iloc[0]}) #getting the first non_NONE gender reported (sex essentially)\n",
    "datapool_control_gender = datapool_control_gender.reset_index()\n",
    "\n",
    "patients_control_gender_female = datapool_control_gender[datapool_control_gender.Gender == 'Female'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "patients_control_gender_male = datapool_control_gender[datapool_control_gender.Gender == 'Male'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "\n",
    "datapool_control_Female = datapool_control.merge(patients_control_gender_female, on = ['patient_sk'], how = 'inner')\n",
    "datapool_control_Male = datapool_control.merge(patients_control_gender_male, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Race ESRD\n",
    "\n",
    "datapool_ESRD_race = datapool_ESRD.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "datapool_ESRD_race = datapool_ESRD_race.reset_index()\n",
    "\n",
    "patients_ESRD_African = datapool_ESRD_race[(datapool_ESRD_race.Race == 'African American')]\n",
    "patients_ESRD_African = patients_ESRD_African.drop('Race', axis = 1)\n",
    "datapool_ESRD_African = datapool_ESRD.merge(patients_ESRD_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patients_ESRD_None_African = datapool_ESRD_race[(datapool_ESRD_race.Race != 'African American')]\n",
    "patients_ESRD_None_African = patients_ESRD_None_African.drop('Race', axis = 1)\n",
    "datapool_ESRD_None_African = datapool_ESRD.merge(patients_ESRD_None_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Race Normal\n",
    "\n",
    "datapool_control_race = datapool_control.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "datapool_control_race = datapool_control_race.reset_index()\n",
    "\n",
    "patients_control_African = datapool_control_race[(datapool_control_race.Race == 'African American')]\n",
    "patients_control_African = patients_control_African.drop('Race', axis = 1)\n",
    "datapool_control_African = datapool_control.merge(patients_control_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patients_control_None_African = datapool_control_race[(datapool_control_race.Race != 'African American')]\n",
    "patients_control_None_African = patients_control_None_African.drop('Race', axis = 1)\n",
    "datapool_control_None_African = datapool_control.merge(patients_control_None_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Hypertenssion\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Hypertension'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypertension'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypertension = list(merged_dataset['Diagnosis_admission_date_Hypertension'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypertension[i]):\n",
    "        Diagnosis_admission_date_Hypertension[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if Diagnosis_admission_date_Hypertension[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypertension[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "    \n",
    "\n",
    "patients_ESRD_Hypertension = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Hypertension = datapool_ESRD.merge(patients_ESRD_Hypertension, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Hypertenssion\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Hypertension = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Hypertension = datapool_ESRD.merge(patients_ESRD_Non_Hypertension, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Diabetes'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Diabetes'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Diabetes = list(merged_dataset['Diagnosis_admission_date_Diabetes'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Diabetes[i]):\n",
    "        Diagnosis_admission_date_Diabetes[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if Diagnosis_admission_date_Diabetes[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Diabetes[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "\n",
    "patients_ESRD_Diabetes = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Diabetes = datapool_ESRD.merge(patients_ESRD_Diabetes, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Diabeties\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Diabetes = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Diabetes = datapool_ESRD.merge(patients_ESRD_Non_Diabetes, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Cardiovascular_Disease\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Coronary_Artery_Disease = list(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Coronary_Artery_Disease[i]):\n",
    "        Diagnosis_admission_date_Coronary_Artery_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if Diagnosis_admission_date_Coronary_Artery_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Coronary_Artery_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Cerebrovascular_Disease = list(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Cerebrovascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Cerebrovascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if Diagnosis_admission_date_Cerebrovascular_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Cerebrovascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Peripheral_Vascular_Disease = list(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Peripheral_Vascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Peripheral_Vascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if Diagnosis_admission_date_Peripheral_Vascular_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Peripheral_Vascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "    \n",
    "\n",
    "patients_ESRD_Cardiovascular_Disease = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Cardiovascular_Disease = datapool_ESRD.merge(patients_ESRD_Cardiovascular_Disease, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Non-Cardiovascular_Disease\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Cardiovascular_Disease = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Cardiovascular_Disease = datapool_ESRD.merge(patients_ESRD_Non_Cardiovascular_Disease, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Diagnosis_admission_date_Hypercholesterolemia\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypercholesterolemia = list(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypercholesterolemia[i]):\n",
    "        Diagnosis_admission_date_Hypercholesterolemia[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if Diagnosis_admission_date_Hypercholesterolemia[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypercholesterolemia[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "\n",
    "patients_ESRD_Hypercholesterolemia = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Hypercholesterolemia = datapool_ESRD.merge(patients_ESRD_Hypercholesterolemia, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Hypercholesterolemia\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Hypercholesterolemia = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Hypercholesterolemia = datapool_ESRD.merge(patients_ESRD_Non_Hypercholesterolemia, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Normal subgroup for the disease\n",
    "patients_control_Hypertension = pd.read_csv('DIAGNOSIS_NORMAL_hypertension.csv')\n",
    "patients_control_Hypertension = patients_control_Hypertension.drop(columns=patients_control_Hypertension.columns[0])\n",
    "datapool_control_Hypertension = datapool_control.merge(patients_control_Hypertension, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Hypertension.patient_sk.unique()))))})\n",
    "datapool_control_Non_Hypertension = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Diabetes = pd.read_csv('DIAGNOSIS_NORMAL_Diabetes.csv')\n",
    "patients_control_Diabetes = patients_control_Diabetes.drop(columns=patients_control_Diabetes.columns[0])\n",
    "datapool_control_Diabetes = datapool_control.merge(patients_control_Diabetes, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Diabetes.patient_sk.unique()))))})\n",
    "datapool_control_Non_Diabetes = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Cardiovascular_Disease = pd.read_csv('DIAGNOSIS_NORMAL_Cardivascular_Disease.csv')\n",
    "patients_control_Cardiovascular_Disease = patients_control_Cardiovascular_Disease.drop(columns=patients_control_Cardiovascular_Disease.columns[0])\n",
    "datapool_control_Cardiovascular_Disease = datapool_control.merge(patients_control_Cardiovascular_Disease, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Cardiovascular_Disease.patient_sk.unique()))))})\n",
    "datapool_control_Non_Cardiovascular_Disease = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Hypercholesterolemia = pd.read_csv('DIAGNOSIS_NORMAL_Hypercholesterolemia.csv')\n",
    "patients_control_Hypercholesterolemia = patients_control_Hypercholesterolemia.drop(columns=patients_control_Hypercholesterolemia.columns[0])\n",
    "datapool_control_Hypercholesterolemia = datapool_control.merge(patients_control_Hypercholesterolemia, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Hypercholesterolemia.patient_sk.unique()))))})\n",
    "datapool_control_Non_Hypercholesterolemia = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "\n",
    "Sub_Groups = [[datapool_ESRD_working_age, datapool_control_working_age], [datapool_ESRD_none_working_age, datapool_control_none_working_age], [datapool_ESRD_Female, datapool_control_Female], [datapool_ESRD_Male, datapool_control_Male], [datapool_ESRD_African, datapool_control_African], [datapool_ESRD_None_African, datapool_control_None_African], [datapool_ESRD_Hypertension, datapool_control_Hypertension], [datapool_ESRD_Non_Hypertension, datapool_control_Non_Hypertension], [datapool_ESRD_Diabetes, datapool_control_Diabetes], [datapool_ESRD_Non_Diabetes, datapool_control_Non_Diabetes], [datapool_ESRD_Cardiovascular_Disease, datapool_control_Cardiovascular_Disease], [datapool_ESRD_Non_Cardiovascular_Disease, datapool_control_Non_Cardiovascular_Disease], [datapool_ESRD_Hypercholesterolemia, datapool_control_Hypercholesterolemia], [datapool_ESRD_Non_Hypercholesterolemia, datapool_control_Non_Hypercholesterolemia]]\n",
    "\n",
    "number_in_groups_ESRD = []\n",
    "number_in_groups_Normal = []\n",
    "for item in Sub_Groups:\n",
    "    number_in_groups_ESRD.append(item[0].patient_sk.unique().shape[0])\n",
    "    number_in_groups_Normal.append(item[1].patient_sk.unique().shape[0])\n",
    "    \n",
    "Sub_grouo_table = pd.DataFrame({'Sub groups' : ['Adults under 65','Adults above 65', 'Female', 'Male', 'African American', 'Other (Non-African American)', 'Hypertension', 'Non Hypertension','Diabetes', 'Non Diabetes', 'Cardiovascular Disease',  'Non Cardiovascular Disease', 'Hypercholesterolemia', 'Non Hypercholesterolemia']})\n",
    "Sub_grouo_table['# of ESRD subgroup'] = number_in_groups_ESRD\n",
    "Sub_grouo_table['# of Normal subgroup'] = number_in_groups_Normal\n",
    "\n",
    "\n",
    "\n",
    "Accuracy_list = []\n",
    "Sensetivity_list = []\n",
    "Specificity_list = []\n",
    "time_to_event_ESRD_mean_list = []\n",
    "time_to_event_ESRD_median_list = []\n",
    "time_to_event_ESRD_serror_list = []\n",
    "mu_list = []\n",
    "sigma_list = []\n",
    "time_to_event_dataset = []\n",
    "n_list_normal = []\n",
    "proportion_list = []\n",
    "\n",
    "for datapool in Sub_Groups:\n",
    "    \n",
    "    datapool_ESRD = datapool[0]\n",
    "    datapool_control = datapool[1]\n",
    "    \n",
    "    # Mu and sigma\n",
    "    \n",
    "\n",
    "    var_list = []\n",
    "    n_list = []\n",
    "\n",
    "    # ____________________________________ Starting point : from CERNER  ____________________________________\n",
    "\n",
    "    #everything is still there from previous analysis\n",
    "    # _________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "    var_list = datapool_control.groupby('patient_sk').agg({'newly_calculated_eGFR_new':'std'})\n",
    "    var_list = list(var_list.newly_calculated_eGFR_new)\n",
    "\n",
    "    n_list =  datapool_control.groupby('patient_sk').agg({'patient_sk':'count'})\n",
    "    n_list = list(n_list.patient_sk)\n",
    "    #calculating the mean and variance of the Normal sample\n",
    "\n",
    "    n_1 = list((n_list - np.ones(len(n_list))).astype('int'))\n",
    "    numerator = np.multiply(n_1, np.power(var_list, 2))\n",
    "    denominator = sum(n_list) - len(n_list)\n",
    "    sigma = np.power(sum(numerator)/denominator,0.5)\n",
    "    sigma= 7.92457416532869\n",
    "    #Hyperparametrs:\n",
    "\n",
    "    V0 = 0\n",
    "    w = 0.75\n",
    "    T = -4\n",
    "\n",
    "\n",
    "    ## AND let us start palying with Zi and Vi\n",
    "    from numba import jit\n",
    "    @jit(nopython=True)\n",
    "\n",
    "    def Vi_creator(newly_calculated_eGFR_new, starting_mu, patient_sk, Age):\n",
    "        Zi = np.zeros(newly_calculated_eGFR_new.shape)\n",
    "        Zi[0] = 0\n",
    "\n",
    "        for i in range(1, Zi.shape[0]):\n",
    "            if patient_sk[i] == patient_sk[i-1]:\n",
    "                delta_age = Age[i] - Age[i-1]\n",
    "                Zi[i] = (newly_calculated_eGFR_new[i] - (starting_mu[i] - 0.81 * (delta_age)))/sigma\n",
    "            else:\n",
    "                Zi[i] = 0\n",
    "\n",
    "\n",
    "        Vi = np.zeros(Zi.shape)\n",
    "        Vi[0] = V0\n",
    "\n",
    "        for i in range(1, Vi.shape[0]):\n",
    "            if patient_sk[i] == patient_sk[i-1]:\n",
    "                Vi[i] = (min(0.0, Zi[i] + w + Vi[i-1]))\n",
    "            else:\n",
    "                Vi[i] = V0\n",
    "\n",
    "        return Vi\n",
    "\n",
    "    datapool_control['Vi'] = Vi_creator(datapool_control['newly_calculated_eGFR_new'].values, datapool_control['starting_mu'].values, datapool_control['patient_sk'].values, datapool_control['Age'].values)\n",
    "    datapool_ESRD['Vi'] = Vi_creator(datapool_ESRD['newly_calculated_eGFR_new'].values, datapool_ESRD['starting_mu'].values, datapool_ESRD['patient_sk'].values, datapool_ESRD['Age'].values)\n",
    "\n",
    "\n",
    "    # Making up the result trigger date and eGFR tables\n",
    "\n",
    "    patients_control_trigger = datapool_control[datapool_control['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_control_trigger = patients_control_trigger.reset_index()\n",
    "    patients_control_trigger = patients_control_trigger.merge(datapool_control[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger[patients_control_trigger.Trigger_date == patients_control_trigger.Date]\n",
    "    patients_control_trigger['New_label'] = list(np.ones(patients_control_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    patients_ESRD_trigger = datapool_ESRD[datapool_ESRD['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.reset_index()\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.merge(datapool_ESRD[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger[patients_ESRD_trigger.Trigger_date == patients_ESRD_trigger.Date]\n",
    "    patients_ESRD_trigger['New_label'] = list(np.ones(patients_ESRD_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    #Labeling and finishing :)\n",
    "\n",
    "    patients_Normal_labeled = pd.DataFrame({'patient_sk' : list(datapool_control.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_control.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_Normal_labeled =  patients_Normal_labeled.merge(patients_control_trigger, on='patient_sk', how='left')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop_duplicates('patient_sk')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    patients_ESRD_labeled = pd.DataFrame({'patient_sk' : list(datapool_ESRD.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_ESRD.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_ESRD_labeled =  patients_ESRD_labeled.merge(patients_ESRD_trigger, on='patient_sk', how='left')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop_duplicates('patient_sk')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop('Date', axis = 1)\n",
    "\n",
    "    #Accuracy = true(positive and negative)/total population\n",
    "    # ESRD NaN = 0.0\n",
    "    # Normal NaN = 0.0\n",
    "\n",
    "    #RIGHT detection in ESRD:\n",
    "    numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    #WRONG detection in Normal\n",
    "    numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "    total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "    # Accuracy\n",
    "    Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "    #Sensetivity\n",
    "    tp = numbet_of_ones_ESRD\n",
    "    fn = total_ESRD - numbet_of_ones_ESRD\n",
    "    Sensetivity = tp/(tp+fn)\n",
    "\n",
    "    #Specificity\n",
    "    tn = total_Normal - numbet_of_ones_Normal\n",
    "    fp = numbet_of_ones_Normal\n",
    "    Specificity = tn/(tn+fp)\n",
    "\n",
    "    Accuracy_list.append(Accuracy)\n",
    "    Sensetivity_list.append(Sensetivity)\n",
    "    Specificity_list.append(Specificity)\n",
    "    \n",
    "    patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "\n",
    "    new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "    patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] = pd.to_datetime(patients_ESRD_labeled['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "    lislis_ESRD = (patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] - patients_ESRD_labeled['Trigger_date'])\n",
    "\n",
    "    patients_ESRD_labeled['time_to_event_ESRD'] = lislis_ESRD\n",
    "    \n",
    "    count_lislis = 0\n",
    "    count_lislis_NaT = 0\n",
    "    for i in range(len(lislis_ESRD)):\n",
    "        if lislis_ESRD[i] >= timedelta(0):\n",
    "            count_lislis = count_lislis + 1\n",
    "        if pd.isnull(lislis_ESRD[i]):\n",
    "            count_lislis_NaT = count_lislis_NaT + 1\n",
    "            \n",
    "            \n",
    "    proportion_list.append(count_lislis/len(list(datapool_ESRD.patient_sk.unique())))  \n",
    "    \n",
    "    patients_ESRD_labeled.loc[patients_ESRD_labeled['time_to_event_ESRD'] <= timedelta(0),'time_to_event_ESRD'] = timedelta(0)\n",
    "    \n",
    "    time_to_event_ESRD_mean = np.mean(patients_ESRD_labeled['time_to_event_ESRD'])\n",
    "    time_to_event_ESRD_median = np.median(patients_ESRD_labeled['time_to_event_ESRD'])\n",
    "    time_to_event_ESRD_serror = np.std(patients_ESRD_labeled['time_to_event_ESRD'])/np.sqrt(len(patients_ESRD_labeled['time_to_event_ESRD']) - count_lislis_NaT)\n",
    "    \n",
    "        \n",
    "    \n",
    "    time_to_event_ESRD_mean_list.append(time_to_event_ESRD_mean)\n",
    "    time_to_event_ESRD_median_list.append(time_to_event_ESRD_median)\n",
    "    time_to_event_ESRD_serror_list.append(time_to_event_ESRD_serror)\n",
    "    \n",
    "    \n",
    "    time_to_event_dataset.append(patients_ESRD_labeled) \n",
    "    \n",
    "\n",
    "#Sub_grouo_table['# of detected / sub-total'] = proportion_list\n",
    "Sub_grouo_table['Mu'] = 'functin of age'\n",
    "Sub_grouo_table['Sigma'] = sigma\n",
    "Sub_grouo_table['Accuracy'] = Accuracy_list\n",
    "Sub_grouo_table['Sensitivity'] = Sensetivity_list\n",
    "Sub_grouo_table['Specificity'] = Specificity_list\n",
    "Sub_grouo_table['Mean time to event (ESRD diagnosis)'] = time_to_event_ESRD_mean_list\n",
    "Sub_grouo_table['Median time to event (ESRD diagnosis)'] = time_to_event_ESRD_median_list\n",
    "Sub_grouo_table['Standard error of time to event (ESRD diagnosis)'] = time_to_event_ESRD_serror_list\n",
    "\n",
    "\n",
    "\n",
    "merged_dataset['time_to_event_ESRD'] = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "merged_dataset_all_positive = merged_dataset.copy()\n",
    "merged_dataset_all_positive.loc[merged_dataset_all_positive['time_to_event_ESRD'] <= timedelta(0), 'time_to_event_ESRD'] = timedelta(0)\n",
    "new_row = {'Sub groups':'Total','# of ESRD subgroup' : 5410, '# of Normal subgroup':85699, 'Mu':'functin of age' , 'Sigma':sigma, 'Accuracy' : 0.8782227880889923, 'Sensitivity' : 0.8972273567467652, 'Specificity': 0.877023069113992, 'Mean time to event (ESRD diagnosis)' : np.mean(merged_dataset_all_positive.time_to_event_ESRD) , 'Median time to event (ESRD diagnosis)' : np.median(merged_dataset_all_positive.time_to_event_ESRD), 'Standard error of time to event (ESRD diagnosis)': np.std(merged_dataset_all_positive['time_to_event_ESRD'])/np.sqrt((4941))}\n",
    "Sub_grouo_table = Sub_grouo_table.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "for item in time_to_event_dataset:\n",
    "    item.time_to_event_ESRD = pd.to_timedelta(item.time_to_event_ESRD, errors='coerce')\n",
    "\n",
    "time_to_event_dataset_Adults_under_65 = time_to_event_dataset[0].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Adults_above_65 = time_to_event_dataset[1].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Female = time_to_event_dataset[2].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Male = time_to_event_dataset[3].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_African_American = time_to_event_dataset[4].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_African_American = time_to_event_dataset[5].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "Sub_grouo_table\n",
    "#Sub_grouo_table.to_csv('Gender_Race_impact_corrected_old_formula.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_grouo_table.to_csv('Final_Sub_Groups_NEW_CUSUM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Age ESRD\n",
    "\n",
    "datapool_ESRD_age = datapool_ESRD.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_ESRD_age = datapool_ESRD_age.reset_index()\n",
    "\n",
    "patient_ESRD_18_25 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 18) & (datapool_ESRD_age.Age < 25)].drop('Age', axis =1)\n",
    "datapool_ESRD_18_25 = datapool_ESRD.merge(patient_ESRD_18_25, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_25_30 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 25) & (datapool_ESRD_age.Age < 30)].drop('Age', axis =1)\n",
    "datapool_ESRD_25_30 = datapool_ESRD.merge(patient_ESRD_25_30, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_30_35 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 30) & (datapool_ESRD_age.Age < 35)].drop('Age', axis =1)\n",
    "datapool_ESRD_30_35 = datapool_ESRD.merge(patient_ESRD_30_35, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_35_40 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 35) & (datapool_ESRD_age.Age < 40)].drop('Age', axis =1)\n",
    "datapool_ESRD_35_40 = datapool_ESRD.merge(patient_ESRD_35_40, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_40_45 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 40) & (datapool_ESRD_age.Age < 45)].drop('Age', axis =1)\n",
    "datapool_ESRD_40_45 = datapool_ESRD.merge(patient_ESRD_40_45, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_45_50 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 45) & (datapool_ESRD_age.Age < 50)].drop('Age', axis =1)\n",
    "datapool_ESRD_45_50 = datapool_ESRD.merge(patient_ESRD_45_50, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_50_55 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 50) & (datapool_ESRD_age.Age < 55)].drop('Age', axis =1)\n",
    "datapool_ESRD_50_55 = datapool_ESRD.merge(patient_ESRD_50_55, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_55_60 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 55) & (datapool_ESRD_age.Age < 60)].drop('Age', axis =1)\n",
    "datapool_ESRD_55_60 = datapool_ESRD.merge(patient_ESRD_55_60, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_60_65 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 60) & (datapool_ESRD_age.Age < 65)].drop('Age', axis =1)\n",
    "datapool_ESRD_60_65 = datapool_ESRD.merge(patient_ESRD_60_65, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_65_70 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 65) & (datapool_ESRD_age.Age < 70)].drop('Age', axis =1)\n",
    "datapool_ESRD_65_70 = datapool_ESRD.merge(patient_ESRD_65_70, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_70_75 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 70) & (datapool_ESRD_age.Age < 75)].drop('Age', axis =1)\n",
    "datapool_ESRD_70_75 = datapool_ESRD.merge(patient_ESRD_70_75, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_75_80 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 75) & (datapool_ESRD_age.Age < 80)].drop('Age', axis =1)\n",
    "datapool_ESRD_75_80 = datapool_ESRD.merge(patient_ESRD_75_80, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_80_85 = datapool_ESRD_age[(datapool_ESRD_age.Age >= 80) & (datapool_ESRD_age.Age < 85)].drop('Age', axis =1)\n",
    "datapool_ESRD_80_85 = datapool_ESRD.merge(patient_ESRD_80_85, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_85_on = datapool_ESRD_age[(datapool_ESRD_age.Age >= 85)].drop('Age', axis =1)\n",
    "datapool_ESRD_85_on = datapool_ESRD.merge(patient_ESRD_85_on, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Age Normal\n",
    "\n",
    "datapool_control_age = datapool_control.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_control_age = datapool_control_age.reset_index()\n",
    "\n",
    "\n",
    "patient_control_18_25 = datapool_control_age[(datapool_control_age.Age >= 18) & (datapool_control_age.Age < 25)].drop('Age', axis =1)\n",
    "datapool_control_18_25 = datapool_control.merge(patient_control_18_25, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_25_30 = datapool_control_age[(datapool_control_age.Age >= 25) & (datapool_control_age.Age < 30)].drop('Age', axis =1)\n",
    "datapool_control_25_30 = datapool_control.merge(patient_control_25_30, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_30_35 = datapool_control_age[(datapool_control_age.Age >= 30) & (datapool_control_age.Age < 35)].drop('Age', axis =1)\n",
    "datapool_control_30_35 = datapool_control.merge(patient_control_30_35, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_35_40 = datapool_control_age[(datapool_control_age.Age >= 35) & (datapool_control_age.Age < 40)].drop('Age', axis =1)\n",
    "datapool_control_35_40 = datapool_control.merge(patient_control_35_40, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_40_45 = datapool_control_age[(datapool_control_age.Age >= 40) & (datapool_control_age.Age < 45)].drop('Age', axis =1)\n",
    "datapool_control_40_45 = datapool_control.merge(patient_control_40_45, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_45_50 = datapool_control_age[(datapool_control_age.Age >= 45) & (datapool_control_age.Age < 50)].drop('Age', axis =1)\n",
    "datapool_control_45_50 = datapool_control.merge(patient_control_45_50, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_50_55 = datapool_control_age[(datapool_control_age.Age >= 50) & (datapool_control_age.Age < 55)].drop('Age', axis =1)\n",
    "datapool_control_50_55 = datapool_control.merge(patient_control_50_55, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_55_60 = datapool_control_age[(datapool_control_age.Age >= 55) & (datapool_control_age.Age < 60)].drop('Age', axis =1)\n",
    "datapool_control_55_60 = datapool_control.merge(patient_control_55_60, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_60_65 = datapool_control_age[(datapool_control_age.Age >= 60) & (datapool_control_age.Age < 65)].drop('Age', axis =1)\n",
    "datapool_control_60_65 = datapool_control.merge(patient_control_60_65, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_65_70 = datapool_control_age[(datapool_control_age.Age >= 65) & (datapool_control_age.Age < 70)].drop('Age', axis =1)\n",
    "datapool_control_65_70 = datapool_control.merge(patient_control_65_70, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_70_75 = datapool_control_age[(datapool_control_age.Age >= 70) & (datapool_control_age.Age < 75)].drop('Age', axis =1)\n",
    "datapool_control_70_75 = datapool_control.merge(patient_control_70_75, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_75_80 = datapool_control_age[(datapool_control_age.Age >= 75) & (datapool_control_age.Age < 80)].drop('Age', axis =1)\n",
    "datapool_control_75_80 = datapool_control.merge(patient_control_75_80, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_80_85 = datapool_control_age[(datapool_control_age.Age >= 80) & (datapool_control_age.Age < 85)].drop('Age', axis =1)\n",
    "datapool_control_80_85 = datapool_control.merge(patient_control_80_85, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_85_on = datapool_control_age[(datapool_control_age.Age >= 85)].drop('Age', axis =1)\n",
    "datapool_control_85_on = datapool_control.merge(patient_control_85_on, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "Sub_Groups = [[datapool_ESRD_18_25, datapool_control_18_25], [datapool_ESRD_25_30, datapool_control_25_30], [datapool_ESRD_30_35, datapool_control_30_35], [datapool_ESRD_35_40, datapool_control_35_40], [datapool_ESRD_40_45, datapool_control_40_45], [datapool_ESRD_45_50, datapool_control_45_50], [datapool_ESRD_50_55, datapool_control_50_55], [datapool_ESRD_55_60, datapool_control_55_60], [datapool_ESRD_60_65, datapool_control_60_65], [datapool_ESRD_65_70, datapool_control_65_70], [datapool_ESRD_70_75, datapool_control_70_75], [datapool_ESRD_75_80, datapool_control_75_80], [datapool_ESRD_80_85, datapool_control_80_85], [datapool_ESRD_85_on, datapool_control_85_on]]\n",
    "\n",
    "number_in_groups_ESRD = []\n",
    "number_in_groups_Normal = []\n",
    "for item in Sub_Groups:\n",
    "    number_in_groups_ESRD.append(item[0].patient_sk.unique().shape[0])\n",
    "    number_in_groups_Normal.append(item[1].patient_sk.unique().shape[0])\n",
    "    \n",
    "Sub_grouo_table = pd.DataFrame({'Sub groups' : ['18_25', '25_30', '30_35', '35_40', '40_45', '45_50', '50_55', '55_60', '60_65', '65_70', '70_75', '75_80', '80_85', '> 85']})\n",
    "Sub_grouo_table['# of ESRD subgroup'] = number_in_groups_ESRD\n",
    "Sub_grouo_table['# of Normal subgroup'] = number_in_groups_Normal\n",
    "\n",
    "\n",
    "Accuracy_list = []\n",
    "Sensetivity_list = []\n",
    "Specificity_list = []\n",
    "time_to_event_ESRD_mean_list = []\n",
    "time_to_event_ESRD_median_list = []\n",
    "time_to_event_ESRD_serror_list = []\n",
    "mu_list = []\n",
    "sigma_list = []\n",
    "time_to_event_dataset = []\n",
    "n_list_normal = []\n",
    "proportion_list = []\n",
    "\n",
    "for datapool in Sub_Groups:\n",
    "    \n",
    "    datapool_ESRD = datapool[0]\n",
    "    datapool_control = datapool[1]\n",
    "    \n",
    "    # Mu and sigma\n",
    "    \n",
    "    \n",
    "    var_list = []\n",
    "    n_list = []\n",
    "\n",
    "    mu = np.mean(datapool_control['newly_calculated_eGFR_new'])\n",
    "\n",
    "    var_list = datapool_control.groupby('patient_sk').agg({'newly_calculated_eGFR_new':'std'})\n",
    "    var_list = list(var_list.newly_calculated_eGFR_new)\n",
    "\n",
    "    n_list =  datapool_control.groupby('patient_sk').agg({'patient_sk':'count'})\n",
    "    n_list = list(n_list.patient_sk)\n",
    "    #calculating the mean and variance of the Normal sample\n",
    "\n",
    "    n_1 = list((n_list - np.ones(len(n_list))).astype('int'))\n",
    "    numerator = np.multiply(n_1, np.power(var_list, 2))\n",
    "    denominator = sum(n_list) - len(n_list)\n",
    "    sigma = np.power(sum(numerator)/denominator,0.5)\n",
    "    \n",
    "    mu_list.append(mu)\n",
    "    sigma_list.append(sigma)\n",
    "    \n",
    "    #Hyperparametrs:\n",
    "\n",
    "    V0 = 0\n",
    "    w = 0.75\n",
    "    T = -4\n",
    "    a = 0.2\n",
    "\n",
    "    ## Zi:\n",
    "\n",
    "    datapool_control['Zi'] = (datapool_control.newly_calculated_eGFR_new - mu)/sigma\n",
    "    datapool_ESRD['Zi'] = (datapool_ESRD.newly_calculated_eGFR_new - mu)/sigma\n",
    "\n",
    "    ## AAANNNDDD let us start palying with Zi and Vi :) AND THE SLOPES AS WELL :)\n",
    "\n",
    "    from numba import jit\n",
    "    @jit(nopython=True)\n",
    "\n",
    "    def Vi_creator(Zi, patient_sk):\n",
    "        Vi = np.zeros(Zi.shape)\n",
    "        Vi[0] = V0\n",
    "\n",
    "        for i in range(1, Vi.shape[0]):\n",
    "            if patient_sk[i] == patient_sk[i-1]:\n",
    "                Vi[i] = (min(0.0, Zi[i] + w + Vi[i-1]))\n",
    "            else:\n",
    "                Vi[i] = V0\n",
    "\n",
    "        return Vi\n",
    "\n",
    "    datapool_control['Vi'] = Vi_creator(datapool_control['Zi'].values, datapool_control['patient_sk'].values)\n",
    "    datapool_ESRD['Vi'] = Vi_creator(datapool_ESRD['Zi'].values, datapool_ESRD['patient_sk'].values)\n",
    "    \n",
    "    # Making up the result trigger date and eGFR tables\n",
    "\n",
    "    patients_control_trigger = datapool_control[datapool_control['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_control_trigger = patients_control_trigger.reset_index()\n",
    "    patients_control_trigger = patients_control_trigger.merge(datapool_control[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger[patients_control_trigger.Trigger_date == patients_control_trigger.Date]\n",
    "    patients_control_trigger['New_label'] = list(np.ones(patients_control_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    patients_ESRD_trigger = datapool_ESRD[datapool_ESRD['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.reset_index()\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.merge(datapool_ESRD[['patient_sk', 'newly_calculated_eGFR_new', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger[patients_ESRD_trigger.Trigger_date == patients_ESRD_trigger.Date]\n",
    "    patients_ESRD_trigger['New_label'] = list(np.ones(patients_ESRD_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    #Labeling and finishing :)\n",
    "\n",
    "    patients_Normal_labeled = pd.DataFrame({'patient_sk' : list(datapool_control.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_control.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_Normal_labeled =  patients_Normal_labeled.merge(patients_control_trigger, on='patient_sk', how='left')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop_duplicates('patient_sk')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    patients_ESRD_labeled = pd.DataFrame({'patient_sk' : list(datapool_ESRD.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_ESRD.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_ESRD_labeled =  patients_ESRD_labeled.merge(patients_ESRD_trigger, on='patient_sk', how='left')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop_duplicates('patient_sk')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop('Date', axis = 1)\n",
    "\n",
    "    #Accuracy = true(positive and negative)/total population\n",
    "    # ESRD NaN = 0.0\n",
    "    # Normal NaN = 0.0\n",
    "\n",
    "    #RIGHT detection in ESRD:\n",
    "    numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    #WRONG detection in Normal\n",
    "    numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "    total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "    # Accuracy\n",
    "    Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "    #Sensetivity\n",
    "    tp = numbet_of_ones_ESRD\n",
    "    fn = total_ESRD - numbet_of_ones_ESRD\n",
    "    Sensetivity = tp/(tp+fn)\n",
    "\n",
    "    #Specificity\n",
    "    tn = total_Normal - numbet_of_ones_Normal\n",
    "    fp = numbet_of_ones_Normal\n",
    "    Specificity = tn/(tn+fp)\n",
    "\n",
    "    Accuracy_list.append(Accuracy)\n",
    "    Sensetivity_list.append(Sensetivity)\n",
    "    Specificity_list.append(Specificity)\n",
    "    \n",
    "    patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "\n",
    "    new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "    patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] = pd.to_datetime(patients_ESRD_labeled['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "    lislis_ESRD = (patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] - patients_ESRD_labeled['Trigger_date'])\n",
    "\n",
    "    patients_ESRD_labeled['time_to_event_ESRD'] = lislis_ESRD\n",
    "    \n",
    "    count_lislis = 0\n",
    "    for i in range(len(lislis_ESRD)):\n",
    "        if lislis_ESRD[i] >= timedelta(0):\n",
    "            count_lislis = count_lislis + 1\n",
    "            \n",
    "    proportion_list.append(count_lislis/len(list(datapool_ESRD.patient_sk.unique())))  \n",
    "    \n",
    "    for i in range(len(lislis_ESRD)):\n",
    "        if lislis_ESRD[i] <= timedelta(0):\n",
    "            patients_ESRD_labeled['time_to_event_ESRD'][i] = timedelta(0)\n",
    "            lislis_ESRD[i] = timedelta(0)\n",
    "    \n",
    "    time_to_event_ESRD_mean = np.mean(lislis_ESRD)\n",
    "    time_to_event_ESRD_median = np.median(lislis_ESRD)\n",
    "    time_to_event_ESRD_serror = np.std(lislis_ESRD, ddof=1)\n",
    "    \n",
    "        \n",
    "    \n",
    "    time_to_event_ESRD_mean_list.append(time_to_event_ESRD_mean)\n",
    "    time_to_event_ESRD_median_list.append(time_to_event_ESRD_median)\n",
    "    time_to_event_ESRD_serror_list.append(time_to_event_ESRD_serror)\n",
    "    \n",
    "    \n",
    "    time_to_event_dataset.append(patients_ESRD_labeled) \n",
    "    \n",
    "\n",
    "Sub_grouo_table['# of detected / sub-total'] = proportion_list\n",
    "Sub_grouo_table['Mu'] = mu_list\n",
    "Sub_grouo_table['Sigma'] = sigma_list\n",
    "Sub_grouo_table['Accuracy'] = Accuracy_list\n",
    "Sub_grouo_table['Sensitivity'] = Sensetivity_list\n",
    "Sub_grouo_table['Specificity'] = Specificity_list\n",
    "Sub_grouo_table['Mean time to event (ESRD diagnosis)'] = time_to_event_ESRD_mean_list\n",
    "Sub_grouo_table['Median time to event (ESRD diagnosis)'] = time_to_event_ESRD_median_list\n",
    "Sub_grouo_table['Standard error of time to event (ESRD diagnosis)'] = time_to_event_ESRD_serror_list/np.sqrt(count_lislis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_dataset['time_to_event_ESRD'] = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "new_row = {'Sub groups':'Total','Mu':mu , 'Sigma':sigma, 'Accuracy' : Accuracy, 'Sensitivity' : Sensetivity, 'Specificity': Specificity, 'Mean time to event (ESRD diagnosis)' : np.mean(merged_dataset.time_to_event_ESRD) , 'Median time to event (ESRD diagnosis)' : np.median(merged_dataset.time_to_event_ESRD)}\n",
    "Sub_grouo_table = Sub_grouo_table.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "for item in time_to_event_dataset:\n",
    "    item.time_to_event_ESRD = pd.to_timedelta(item.time_to_event_ESRD, errors='coerce')\n",
    "\n",
    "time_to_event_dataset_Adults_under_65 = time_to_event_dataset[0].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Adults_above_65 = time_to_event_dataset[1].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Female = time_to_event_dataset[2].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Male = time_to_event_dataset[3].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_African_American = time_to_event_dataset[4].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_African_American = time_to_event_dataset[5].drop('Label', axis = 1).drop(['Trigger_date', 'newly_calculated_eGFR_new', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "Sub_grouo_table\n",
    "#Sub_grouo_table.to_csv('Age_impact_new_formula.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    if i.total_seconds() >= 0 | pd.isnull(i) == False:\n",
    "        y.append(i.total_seconds()/(2.628e+6))\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"Earliness, in months\", ylabel = \"Frequency\")\n",
    "ax.set(xlim=(250, 0))\n",
    "ax.invert_xaxis()\n",
    "plt.savefig('plot3_2022_new_cusum_anew.jpg', orientation=\"landscape\",\n",
    "           dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize= (15,10))\n",
    "\n",
    "#time_origin = datetime.strptime('2020-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "patient_sks = [134769713, 194590220, 125108635, 121768243]\n",
    "i = 0;\n",
    "\n",
    "for ax in axes:\n",
    "    for hi in ax:\n",
    "        hi.scatter(datapool_ESRD[datapool_ESRD['patient_sk'] == patient_sks[i]]['Date'].values, datapool_ESRD[datapool_ESRD['patient_sk'] == patient_sks[i]]['newly_calculated_eGFR_new'].values, marker='o',color=\"steelblue\")\n",
    "        hi.axvline(x=time_origin, color=\"white\", lw=2)\n",
    "        hi.set_ylabel('eGFR')\n",
    "        hi.set_xlabel('Date')\n",
    "        hi.set_ylim([0,120])\n",
    "        hi.set_title('{}, {}, {},y.o'.format(datapool_ESRD[datapool_ESRD['patient_sk'] == patient_sks[i]]['Gender'].values[0], datapool_ESRD[datapool_ESRD['patient_sk'] == patient_sks[i]]['Race'].values[0], int(datapool_ESRD[datapool_ESRD['patient_sk'] == patient_sks[i]]['Age'].values[0])))\n",
    "        hi.grid()\n",
    "        i = i + 1\n",
    "\n",
    "plt.savefig('sample_ESKD_patients.jpg', orientation=\"landscape\",\n",
    "           dpi=300)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "merged_dataset = patients_ESRD_labeled\n",
    "\n",
    "new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "merged_dataset = merged_dataset.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "lislis_ESRD = (merged_dataset['Diagnosis_admission_date_ESRD'] - merged_dataset['Trigger_date'])\n",
    "\n",
    "merged_dataset['time_to_event_ESRD'] = lislis_ESRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"white\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients\", ylabel = \"Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"whitegrid\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax ,  kde_kws = {'cumulative': True})\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients - Cumulative plot \", ylabel = \"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    if i.total_seconds() >= 0 | pd.isnull(i) == False:\n",
    "        y.append(i.total_seconds()/(2.628e+6))\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax, kde=False)\n",
    "ax.set(xlabel=\"Earliness, in months\", ylabel = \"Frequency\")\n",
    "ax.set(xlim=(250, 0))\n",
    "ax.invert_xaxis()\n",
    "plt.savefig('plot3.jpg', orientation=\"landscape\",\n",
    "           dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    if i.total_seconds() >= 0 | pd.isnull(i) == False:\n",
    "        y.append(i.total_seconds()/(2.628e+6))\n",
    "    \n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax)\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs\", ylabel = \"Probability\")\n",
    "ax.set(xlim=(250, 0))\n",
    "ax.invert_xaxis()\n",
    "plt.savefig('plot3.jpg', orientation=\"landscape\",\n",
    "           dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sns.set_style(\"whitegrid\")\n",
    "yyy = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "\n",
    "y = []\n",
    "for i in yyy:\n",
    "    y.append(i.total_seconds()/2.628e+6)\n",
    "\n",
    "#Plot Data\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "sns.distplot(y, bins=100, color=\"darkslategray\", ax=ax ,  kde_kws = {'cumulative': True})\n",
    "ax.set(xlabel=\"How early (in months) the risk trigger occurs, for 5410 patients - Cumulative plot \", ylabel = \"\")\n",
    "\n",
    "ax.set(ylim=(0.23, 1))\n",
    "ax.set(xlim=(0, 250))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For further information please contact rzz5164@psu.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
