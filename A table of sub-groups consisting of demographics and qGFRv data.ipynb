{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a table of sub-groups consisting of demographics and CUSUM-GFR data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * This code belongs to the paper \"Using CUSUM in real time to signal clinically relevant decreases in estimated glomerular filtration rate\"\n",
    "##### To cite: Zafarnejad, R., Dumbauld, S., Dumbauld, D. et al. Using CUSUM in real time to signal clinically relevant decreases in estimated glomerular filtration rate. BMC Nephrol 23, 287 (2022). https://doi.org/10.1186/s12882-022-02910-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_data = pd.read_csv(\"DIAGNOSIS_2.csv\")\n",
    "\n",
    "full_date_dataset = pd.read_csv('merged_dataset_dates_timedeltas_full.csv')\n",
    "merged_dataset = full_date_dataset.merge(diagnosis_data, on = 'patient_sk' , how = 'inner')\n",
    "merged_dataset = merged_dataset.rename(columns={'eGFR_EPI': 'Trigger_eGFR'})\n",
    "\n",
    "datapool_ESRD = pd.read_csv('Final_ESRD_group_done_pandas.csv')\n",
    "datapool_ESRD = datapool_ESRD.drop(columns=datapool_ESRD.columns[0])\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "datapool_control = pd.read_csv(\"Final_Normal_group_done_pandas.csv\")\n",
    "datapool_control = datapool_control.drop(columns=datapool_control.columns[0])\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_ESRD_dropped = datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_ESRD.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_ESRD_dropped = datapool_ESRD_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_control = datapool_control.drop(datapool_control.index[np.isinf(datapool_control.eGFR_EPI) == True], axis = 0)\n",
    "datapool_control = datapool_control.drop_duplicates()\n",
    "\n",
    "#some patients have less than 9 datapoinsts!!! AFTER DROPPING DUPLICATES\n",
    "datapool_control_dropped = datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index()[datapool_control.groupby('patient_sk').agg({'eGFR_EPI' : 'count'}).reset_index().eGFR_EPI >=9]\n",
    "datapool_control_dropped = datapool_control_dropped.drop('eGFR_EPI', axis =1)\n",
    "datapool_control = datapool_control.merge(datapool_control_dropped, on = 'patient_sk', how = 'inner')\n",
    "\n",
    "#Pulling out each patient's data \n",
    "#Also. sortinh the data by cSr lavel measurement data and reindexing it\n",
    "\n",
    "patients_list_Normal = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5410\n",
      "85699\n"
     ]
    }
   ],
   "source": [
    "# !!!! SHOULD TURN TO TOTAL_SECONDS IN THE MIDST OF ALGORITHM\n",
    "\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD['Date'] = pd.to_datetime(datapool_ESRD['Date'])\n",
    "datapool_ESRD_dates = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_dates = datapool_ESRD_dates.reset_index()\n",
    "datapool_ESRD = datapool_ESRD.merge(datapool_ESRD_dates, on = 'patient_sk', how='left')\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_x'] - datapool_ESRD['Date_y']\n",
    "datapool_ESRD = datapool_ESRD.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_ESRD = datapool_ESRD.drop('Date_y', axis = 1)\n",
    "datapool_ESRD['Date_seconds'] = datapool_ESRD['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control['Date'] = pd.to_datetime(datapool_control['Date'])\n",
    "datapool_control_dates = datapool_control.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_control_dates = datapool_control_dates.reset_index()\n",
    "datapool_control = datapool_control.merge(datapool_control_dates, on = 'patient_sk', how='left')\n",
    "datapool_control['Date_seconds'] = (datapool_control['Date_x'] - datapool_control['Date_y'])\n",
    "datapool_control = datapool_control.rename({'Date_x':'Date'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('Date_y', axis = 1)\n",
    "datapool_control['Date_seconds'] = datapool_control['Date_seconds'].dt.total_seconds()\n",
    "\n",
    "#Getting rid of ESRD min eGFR < 60\n",
    "\n",
    "datapool_ESRD_patients = datapool_ESRD.groupby('patient_sk').agg({'Date': 'min'})\n",
    "datapool_ESRD_patients = datapool_ESRD_patients.reset_index()\n",
    "\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD.merge(datapool_ESRD_patients, on=['patient_sk', 'Date'], how ='inner')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR.drop_duplicates('patient_sk')\n",
    "datapool_ESRD_patients_eGFR = datapool_ESRD_patients_eGFR[datapool_ESRD_patients_eGFR['eGFR_EPI']>=60]\n",
    "\n",
    "datapool_ESRD_new = datapool_ESRD.merge(datapool_ESRD_patients_eGFR['patient_sk'], on = 'patient_sk', how = 'inner')\n",
    "\n",
    "datapool_ESRD = datapool_ESRD_new\n",
    "datapool_ESRD = datapool_ESRD.drop_duplicates()\n",
    "patients_list_ESRD = list(set(np.unique(list(datapool_ESRD['patient_sk']))))\n",
    "\n",
    "print(datapool_ESRD.patient_sk.unique().shape[0])\n",
    "\n",
    "#Getting rid of Normal min eGFR < 60\n",
    "\n",
    "datapool_control_patients = datapool_control.groupby('patient_sk').agg({'eGFR_EPI': 'min'})\n",
    "datapool_control_patients = datapool_control_patients[datapool_control_patients['eGFR_EPI']>=60]\n",
    "datapool_control_patients = datapool_control_patients.reset_index()\n",
    "\n",
    "datapool_control = datapool_control_patients.merge(datapool_control, on = 'patient_sk', how = 'inner')\n",
    "datapool_control = datapool_control.rename({'eGFR_EPI_y':'eGFR_EPI'}, axis = 1)\n",
    "datapool_control = datapool_control.drop('eGFR_EPI_x', axis = 1)\n",
    "\n",
    "patients_list_control_above_50 = list(set(np.unique(list(datapool_control['patient_sk']))))\n",
    "\n",
    "patients_list_Normal = patients_list_control_above_50\n",
    "\n",
    "print(datapool_control.patient_sk.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now, taking care of the sub-groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age ESRD\n",
    "\n",
    "datapool_ESRD_age = datapool_ESRD.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_ESRD_age = datapool_ESRD_age.reset_index()\n",
    "\n",
    "patient_ESRD_working_age = datapool_ESRD_age[datapool_ESRD_age.Age < 65].drop('Age', axis =1)\n",
    "datapool_ESRD_working_age = datapool_ESRD.merge(patient_ESRD_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_ESRD_none_working_age = datapool_ESRD_age[datapool_ESRD_age.Age >= 65].drop('Age', axis =1)\n",
    "datapool_ESRD_none_working_age = datapool_ESRD.merge(patient_ESRD_none_working_age, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age Normal\n",
    "\n",
    "datapool_control_age = datapool_control.groupby('patient_sk').agg({'Age': lambda x: (x.iloc[-1] + x.iloc[0])/2}) #getting median of reported ages\n",
    "datapool_control_age = datapool_control_age.reset_index()\n",
    "\n",
    "patient_control_working_age = datapool_control_age[datapool_control_age.Age < 65].drop('Age', axis =1)\n",
    "datapool_control_working_age = datapool_control.merge(patient_control_working_age, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patient_control_none_working_age = datapool_control_age[datapool_control_age.Age >= 65].drop('Age', axis =1)\n",
    "datapool_control_none_working_age = datapool_control.merge(patient_control_none_working_age, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender ESRD\n",
    "\n",
    "datapool_ESRD_gender = datapool_ESRD[(datapool_ESRD.Gender == 'Female') | (datapool_ESRD.Gender == 'Male')]\n",
    "datapool_ESRD_gender = datapool_ESRD_gender.groupby('patient_sk').agg({'Gender': lambda x: x.iloc[0]}) #getting the first non_NONE gender reported (sex essentially)\n",
    "datapool_ESRD_gender = datapool_ESRD_gender.reset_index()\n",
    "\n",
    "patients_ESRD_gender_female = datapool_ESRD_gender[datapool_ESRD_gender.Gender == 'Female'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "patients_ESRD_gender_male = datapool_ESRD_gender[datapool_ESRD_gender.Gender == 'Male'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "\n",
    "datapool_ESRD_Female = datapool_ESRD.merge(patients_ESRD_gender_female, on = ['patient_sk'], how = 'inner')\n",
    "datapool_ESRD_Male = datapool_ESRD.merge(patients_ESRD_gender_male, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender Normal\n",
    "\n",
    "datapool_control_gender = datapool_control[(datapool_control.Gender == 'Female') | (datapool_control.Gender == 'Male')]\n",
    "datapool_control_gender = datapool_control_gender.groupby('patient_sk').agg({'Gender': lambda x: x.iloc[0]}) #getting the first non_NONE gender reported (sex essentially)\n",
    "datapool_control_gender = datapool_control_gender.reset_index()\n",
    "\n",
    "patients_control_gender_female = datapool_control_gender[datapool_control_gender.Gender == 'Female'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "patients_control_gender_male = datapool_control_gender[datapool_control_gender.Gender == 'Male'].drop_duplicates('patient_sk').drop('Gender', axis = 1)\n",
    "\n",
    "datapool_control_Female = datapool_control.merge(patients_control_gender_female, on = ['patient_sk'], how = 'inner')\n",
    "datapool_control_Male = datapool_control.merge(patients_control_gender_male, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Race Normal\n",
    "\n",
    "datapool_ESRD_race = datapool_ESRD.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "datapool_ESRD_race = datapool_ESRD_race.reset_index()\n",
    "\n",
    "patients_ESRD_African = datapool_ESRD_race[(datapool_ESRD_race.Race == 'African American')]\n",
    "patients_ESRD_African = patients_ESRD_African.drop('Race', axis = 1)\n",
    "datapool_ESRD_African = datapool_ESRD.merge(patients_ESRD_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patients_ESRD_None_African = datapool_ESRD_race[(datapool_ESRD_race.Race != 'African American')]\n",
    "patients_ESRD_None_African = patients_ESRD_None_African.drop('Race', axis = 1)\n",
    "datapool_ESRD_None_African = datapool_ESRD.merge(patients_ESRD_None_African, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Race Normal\n",
    "\n",
    "datapool_control_race = datapool_control.groupby('patient_sk').agg({'Race': lambda x: x.iloc[-1]}) #getting the last non_NONE race reported\n",
    "datapool_control_race = datapool_control_race.reset_index()\n",
    "\n",
    "patients_control_African = datapool_control_race[(datapool_control_race.Race == 'African American')]\n",
    "patients_control_African = patients_control_African.drop('Race', axis = 1)\n",
    "datapool_control_African = datapool_control.merge(patients_control_African, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "patients_control_None_African = datapool_control_race[(datapool_control_race.Race != 'African American')]\n",
    "patients_control_None_African = patients_control_None_African.drop('Race', axis = 1)\n",
    "datapool_control_None_African = datapool_control.merge(patients_control_None_African, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertenssion\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Hypertension'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypertension'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypertension = list(merged_dataset['Diagnosis_admission_date_Hypertension'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypertension[i]):\n",
    "        Diagnosis_admission_date_Hypertension[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypertension)):\n",
    "    if Diagnosis_admission_date_Hypertension[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypertension[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "    \n",
    "\n",
    "patients_ESRD_Hypertension = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Hypertension = datapool_ESRD.merge(patients_ESRD_Hypertension, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Hypertenssion\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Hypertension = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Hypertension = datapool_ESRD.merge(patients_ESRD_Non_Hypertension, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['Diagnosis_admission_date_Diabetes'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Diabetes'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Diabetes = list(merged_dataset['Diagnosis_admission_date_Diabetes'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Diabetes[i]):\n",
    "        Diagnosis_admission_date_Diabetes[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Diabetes)):\n",
    "    if Diagnosis_admission_date_Diabetes[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Diabetes[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "        \n",
    "\n",
    "patients_ESRD_Diabetes = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Diabetes = datapool_ESRD.merge(patients_ESRD_Diabetes, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Diabeties\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Diabetes = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Diabetes = datapool_ESRD.merge(patients_ESRD_Non_Diabetes, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cardiovascular_Disease\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Coronary_Artery_Disease = list(merged_dataset['Diagnosis_admission_date_Coronary_Artery_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Coronary_Artery_Disease[i]):\n",
    "        Diagnosis_admission_date_Coronary_Artery_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Coronary_Artery_Disease)):\n",
    "    if Diagnosis_admission_date_Coronary_Artery_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Coronary_Artery_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Cerebrovascular_Disease = list(merged_dataset['Diagnosis_admission_date_Cerebrovascular_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Cerebrovascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Cerebrovascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Cerebrovascular_Disease)):\n",
    "    if Diagnosis_admission_date_Cerebrovascular_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Cerebrovascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Peripheral_Vascular_Disease = list(merged_dataset['Diagnosis_admission_date_Peripheral_Vascular_Disease'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Peripheral_Vascular_Disease[i]):\n",
    "        Diagnosis_admission_date_Peripheral_Vascular_Disease[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Peripheral_Vascular_Disease)):\n",
    "    if Diagnosis_admission_date_Peripheral_Vascular_Disease[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Peripheral_Vascular_Disease[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "    \n",
    "\n",
    "patients_ESRD_Cardiovascular_Disease = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Cardiovascular_Disease = datapool_ESRD.merge(patients_ESRD_Cardiovascular_Disease, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "\n",
    "#Non-Cardiovascular_Disease\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Cardiovascular_Disease = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Cardiovascular_Disease = datapool_ESRD.merge(patients_ESRD_Non_Cardiovascular_Disease, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnosis_admission_date_Hypercholesterolemia\n",
    "\n",
    "merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'], errors='coerce')\n",
    "merged_dataset['Diagnosis_admission_date_ESRD'] = pd.to_datetime(merged_dataset['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "Diagnosis_admission_date_Hypercholesterolemia = list(merged_dataset['Diagnosis_admission_date_Hypercholesterolemia'])\n",
    "Diagnosis_admission_date_ESRD = list(merged_dataset['Diagnosis_admission_date_ESRD'])\n",
    "\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if pd.isnull(Diagnosis_admission_date_Hypercholesterolemia[i]):\n",
    "        Diagnosis_admission_date_Hypercholesterolemia[i] = pd.Timestamp('1800-01-01')\n",
    "\n",
    "count = 0\n",
    "count_list = []\n",
    "for i in range(len(Diagnosis_admission_date_Hypercholesterolemia)):\n",
    "    if Diagnosis_admission_date_Hypercholesterolemia[i] <= Diagnosis_admission_date_ESRD[i] and Diagnosis_admission_date_Hypercholesterolemia[i] != pd.Timestamp('1800-01-01'):\n",
    "        count = count + 1\n",
    "        count_list.append(merged_dataset['patient_sk'][i])\n",
    "\n",
    "\n",
    "patients_ESRD_Hypercholesterolemia = pd.DataFrame({'patient_sk' : count_list})\n",
    "datapool_ESRD_Hypercholesterolemia = datapool_ESRD.merge(patients_ESRD_Hypercholesterolemia, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "#Non-Hypercholesterolemia\n",
    "\n",
    "patients_list_ESRD\n",
    "patients_ESRD_Non_Hypercholesterolemia = pd.DataFrame({'patient_sk' : list(set(patients_list_ESRD).difference(set(count_list)))})\n",
    "datapool_ESRD_Non_Hypercholesterolemia = datapool_ESRD.merge(patients_ESRD_Non_Hypercholesterolemia, on = ['patient_sk'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_control_Hypertension = pd.read_csv('DIAGNOSIS_NORMAL_hypertension.csv')\n",
    "patients_control_Hypertension = patients_control_Hypertension.drop(columns=patients_control_Hypertension.columns[0])\n",
    "datapool_control_Hypertension = datapool_control.merge(patients_control_Hypertension, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Hypertension.patient_sk.unique()))))})\n",
    "datapool_control_Non_Hypertension = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "datapool_control_Non_Hypertension.patient_sk.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, putting the algorithm together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal subgroup for the disease\n",
    "patients_control_Hypertension = pd.read_csv('DIAGNOSIS_NORMAL_hypertension.csv')\n",
    "patients_control_Hypertension = patients_control_Hypertension.drop(columns=patients_control_Hypertension.columns[0])\n",
    "datapool_control_Hypertension = datapool_control.merge(patients_control_Hypertension, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Hypertension.patient_sk.unique()))))})\n",
    "datapool_control_Non_Hypertension = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Diabetes = pd.read_csv('DIAGNOSIS_NORMAL_Diabetes.csv')\n",
    "patients_control_Diabetes = patients_control_Diabetes.drop(columns=patients_control_Diabetes.columns[0])\n",
    "datapool_control_Diabetes = datapool_control.merge(patients_control_Diabetes, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Diabetes.patient_sk.unique()))))})\n",
    "datapool_control_Non_Diabetes = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Cardiovascular_Disease = pd.read_csv('DIAGNOSIS_NORMAL_Cardivascular_Disease.csv')\n",
    "patients_control_Cardiovascular_Disease = patients_control_Cardiovascular_Disease.drop(columns=patients_control_Cardiovascular_Disease.columns[0])\n",
    "datapool_control_Cardiovascular_Disease = datapool_control.merge(patients_control_Cardiovascular_Disease, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Cardiovascular_Disease.patient_sk.unique()))))})\n",
    "datapool_control_Non_Cardiovascular_Disease = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')\n",
    "\n",
    "patients_control_Hypercholesterolemia = pd.read_csv('DIAGNOSIS_NORMAL_Hypercholesterolemia.csv')\n",
    "patients_control_Hypercholesterolemia = patients_control_Hypercholesterolemia.drop(columns=patients_control_Hypercholesterolemia.columns[0])\n",
    "datapool_control_Hypercholesterolemia = datapool_control.merge(patients_control_Hypercholesterolemia, on = ['patient_sk'], how='inner')\n",
    "patient_lislis = pd.DataFrame({'patient_sk':list(set(list(datapool_control.patient_sk))-(set(list(patients_control_Hypercholesterolemia.patient_sk.unique()))))})\n",
    "datapool_control_Non_Hypercholesterolemia = datapool_control.merge(patient_lislis, on = ['patient_sk'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_Groups = [[datapool_ESRD_working_age, datapool_control_working_age], [datapool_ESRD_none_working_age, datapool_control_none_working_age], [datapool_ESRD_Female, datapool_control_Female],  [datapool_ESRD_Male, datapool_control_Male], [datapool_ESRD_African, datapool_control_African], [datapool_ESRD_None_African, datapool_control_None_African], [datapool_ESRD_Hypertension, datapool_control_Hypertension], [datapool_ESRD_Non_Hypertension, datapool_control_Non_Hypertension], [datapool_ESRD_Diabetes, datapool_control_Diabetes], [datapool_ESRD_Non_Diabetes, datapool_control_Non_Diabetes ],  [datapool_ESRD_Cardiovascular_Disease, datapool_control_Cardiovascular_Disease], [datapool_ESRD_Non_Cardiovascular_Disease, datapool_control_Non_Cardiovascular_Disease], [datapool_ESRD_Hypercholesterolemia, datapool_control_Hypercholesterolemia], [datapool_ESRD_Non_Hypercholesterolemia, datapool_control_Non_Hypercholesterolemia], [datapool_ESRD, datapool_control]]\n",
    "\n",
    "Sub_grouo_table = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_Groups = [[datapool_ESRD_working_age, datapool_control_working_age], [datapool_ESRD_none_working_age, datapool_control_none_working_age], [datapool_ESRD_Female, datapool_control_Female], [datapool_ESRD_Male, datapool_control_Male], [datapool_ESRD_African, datapool_control_African], [datapool_ESRD_None_African, datapool_control_None_African], [datapool_ESRD_Hypertension, datapool_control_Hypertension], [datapool_ESRD_Non_Hypertension, datapool_control_Non_Hypertension], [datapool_ESRD_Diabetes, datapool_control_Diabetes], [datapool_ESRD_Non_Diabetes, datapool_control_Non_Diabetes], [datapool_ESRD_Cardiovascular_Disease, datapool_control_Cardiovascular_Disease], [datapool_ESRD_Non_Cardiovascular_Disease, datapool_control_Non_Cardiovascular_Disease], [datapool_ESRD_Hypercholesterolemia, datapool_control_Hypercholesterolemia], [datapool_ESRD_Non_Hypercholesterolemia, datapool_control_Non_Hypercholesterolemia], [datapool_ESRD, datapool_control]]\n",
    "\n",
    "number_in_groups_ESRD = []\n",
    "number_in_groups_Normal = []\n",
    "for item in Sub_Groups:\n",
    "    number_in_groups_ESRD.append(item[0].patient_sk.unique().shape[0])\n",
    "    number_in_groups_Normal.append(item[1].patient_sk.unique().shape[0])\n",
    "    \n",
    "Sub_grouo_table = pd.DataFrame({'Sub groups' : ['Adults under 65','Adults above 65', 'Female', 'Male', 'African American', 'Other (Non-African American)', 'Hypertension', 'Non Hypertension','Diabetes', 'Non Diabetes', 'Cardiovascular Disease',  'Non Cardiovascular Disease', 'Hypercholesterolemia', 'Non Hypercholesterolemia', 'ALL']})\n",
    "Sub_grouo_table['# of ESRD subgroup'] = number_in_groups_ESRD\n",
    "Sub_grouo_table['# of Normal subgroup'] = number_in_groups_Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_list = []\n",
    "Sensetivity_list = []\n",
    "Specificity_list = []\n",
    "time_to_event_ESRD_mean_list = []\n",
    "time_to_event_ESRD_median_list = []\n",
    "time_to_event_ESRD_serror_list = []\n",
    "mu_list = []\n",
    "sigma_list = []\n",
    "time_to_event_dataset = []\n",
    "n_list_normal = []\n",
    "proportion_list = []\n",
    "\n",
    "for datapool in Sub_Groups:\n",
    "    \n",
    "    datapool_ESRD = datapool[0]\n",
    "    datapool_control = datapool[1]\n",
    "    \n",
    "    # Mu and sigma\n",
    "    \n",
    "    \n",
    "    var_list = []\n",
    "    n_list = []\n",
    "\n",
    "    mu = np.mean(datapool_control['eGFR_EPI'])\n",
    "\n",
    "    var_list = datapool_control.groupby('patient_sk').agg({'eGFR_EPI':'std'})\n",
    "    var_list = list(var_list.eGFR_EPI)\n",
    "\n",
    "    n_list =  datapool_control.groupby('patient_sk').agg({'patient_sk':'count'})\n",
    "    n_list = list(n_list.patient_sk)\n",
    "    #calculating the mean and variance of the Normal sample\n",
    "\n",
    "    n_1 = list((n_list - np.ones(len(n_list))).astype('int'))\n",
    "    numerator = np.multiply(n_1, np.power(var_list, 2))\n",
    "    denominator = sum(n_list) - len(n_list)\n",
    "    sigma = np.power(sum(numerator)/denominator,0.5)\n",
    "    \n",
    "    mu_list.append(mu)\n",
    "    sigma_list.append(sigma)\n",
    "    \n",
    "    #Hyperparametrs:\n",
    "\n",
    "    V0 = 0\n",
    "    w = 0.75\n",
    "    T = -4\n",
    "    a = 0.2\n",
    "\n",
    "    ## Zi:\n",
    "\n",
    "    datapool_control['Zi'] = (datapool_control.eGFR_EPI - mu)/sigma\n",
    "    datapool_ESRD['Zi'] = (datapool_ESRD.eGFR_EPI - mu)/sigma\n",
    "\n",
    "    ## AAANNNDDD let us start palying with Zi and Vi :) AND THE SLOPES AS WELL :)\n",
    "\n",
    "    from numba import jit\n",
    "    @jit(nopython=True)\n",
    "\n",
    "    def Vi_creator(Zi, patient_sk):\n",
    "        Vi = np.zeros(Zi.shape)\n",
    "        Vi[0] = V0\n",
    "\n",
    "        for i in range(1, Vi.shape[0]):\n",
    "            if patient_sk[i] == patient_sk[i-1]:\n",
    "                Vi[i] = (min(0.0, Zi[i] + w + Vi[i-1]))\n",
    "            else:\n",
    "                Vi[i] = V0\n",
    "\n",
    "        return Vi\n",
    "\n",
    "    datapool_control['Vi'] = Vi_creator(datapool_control['Zi'].values, datapool_control['patient_sk'].values)\n",
    "    datapool_ESRD['Vi'] = Vi_creator(datapool_ESRD['Zi'].values, datapool_ESRD['patient_sk'].values)\n",
    "    \n",
    "    # Making up the result trigger date and eGFR tables\n",
    "\n",
    "    patients_control_trigger = datapool_control[datapool_control['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_control_trigger = patients_control_trigger.reset_index()\n",
    "    patients_control_trigger = patients_control_trigger.merge(datapool_control[['patient_sk', 'eGFR_EPI', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_control_trigger = patients_control_trigger[patients_control_trigger.Trigger_date == patients_control_trigger.Date]\n",
    "    patients_control_trigger['New_label'] = list(np.ones(patients_control_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    patients_ESRD_trigger = datapool_ESRD[datapool_ESRD['Vi'] <= T].groupby('patient_sk').agg({'Date': 'min'})\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.reset_index()\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.merge(datapool_ESRD[['patient_sk', 'eGFR_EPI', 'Date']], on=['patient_sk'], how='inner')\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_x':'Trigger_date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger.rename({'Date_y':'Date'}, axis = 1)\n",
    "    patients_ESRD_trigger = patients_ESRD_trigger[patients_ESRD_trigger.Trigger_date == patients_ESRD_trigger.Date]\n",
    "    patients_ESRD_trigger['New_label'] = list(np.ones(patients_ESRD_trigger.patient_sk.shape[0]))\n",
    "\n",
    "    #Labeling and finishing :)\n",
    "\n",
    "    patients_Normal_labeled = pd.DataFrame({'patient_sk' : list(datapool_control.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_control.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_Normal_labeled =  patients_Normal_labeled.merge(patients_control_trigger, on='patient_sk', how='left')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop_duplicates('patient_sk')\n",
    "    patients_Normal_labeled = patients_Normal_labeled.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    patients_ESRD_labeled = pd.DataFrame({'patient_sk' : list(datapool_ESRD.patient_sk.unique()) , 'Label' : list(np.ones(len(list(datapool_ESRD.patient_sk.unique()))))}) \n",
    "\n",
    "    patients_ESRD_labeled =  patients_ESRD_labeled.merge(patients_ESRD_trigger, on='patient_sk', how='left')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop_duplicates('patient_sk')\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.drop('Date', axis = 1)\n",
    "\n",
    "    #Accuracy = true(positive and negative)/total population\n",
    "    # ESRD NaN = 0.0\n",
    "    # Normal NaN = 0.0\n",
    "\n",
    "    #RIGHT detection in ESRD:\n",
    "    numbet_of_ones_ESRD = patients_ESRD_labeled[patients_ESRD_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    #WRONG detection in Normal\n",
    "    numbet_of_ones_Normal = patients_Normal_labeled[patients_Normal_labeled['New_label'] == 1].shape[0]\n",
    "\n",
    "    total_ESRD = patients_ESRD_labeled.shape[0]\n",
    "    total_Normal = patients_Normal_labeled.shape[0]\n",
    "\n",
    "    # Accuracy\n",
    "    Accuracy = (numbet_of_ones_ESRD + (total_Normal - numbet_of_ones_Normal))/(total_ESRD + total_Normal)\n",
    "\n",
    "    #Sensetivity\n",
    "    tp = numbet_of_ones_ESRD\n",
    "    fn = total_ESRD - numbet_of_ones_ESRD\n",
    "    Sensetivity = tp/(tp+fn)\n",
    "\n",
    "    #Specificity\n",
    "    tn = total_Normal - numbet_of_ones_Normal\n",
    "    fp = numbet_of_ones_Normal\n",
    "    Specificity = tn/(tn+fp)\n",
    "\n",
    "    Accuracy_list.append(Accuracy)\n",
    "    Sensetivity_list.append(Sensetivity)\n",
    "    Specificity_list.append(Specificity)\n",
    "    \n",
    "    patients_ESRD_full_dates_pandas = pd.read_csv('Final_patients_ESRD_full_dates_pandas.csv')\n",
    "\n",
    "\n",
    "    new_table_dates = pd.DataFrame({'patient_sk' : patients_ESRD_full_dates_pandas['patient_sk'], 'Diagnosis_admission_date_ESRD' : patients_ESRD_full_dates_pandas['Diagnosis_admission_date_ESRD']})\n",
    "    patients_ESRD_labeled = patients_ESRD_labeled.merge(new_table_dates, on = ['patient_sk'], how = 'inner')\n",
    "\n",
    "    patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] = pd.to_datetime(patients_ESRD_labeled['Diagnosis_admission_date_ESRD'], errors='coerce')\n",
    "\n",
    "    lislis_ESRD = (patients_ESRD_labeled['Diagnosis_admission_date_ESRD'] - patients_ESRD_labeled['Trigger_date'])\n",
    "\n",
    "    patients_ESRD_labeled['time_to_event_ESRD'] = lislis_ESRD\n",
    "    \n",
    "    count_lislis = 0\n",
    "    for i in range(len(lislis_ESRD)):\n",
    "        if lislis_ESRD[i] >= datetime.timedelta(0):\n",
    "            count_lislis = count_lislis + 1\n",
    "            \n",
    "    proportion_list.append(count_lislis/len(list(datapool_ESRD.patient_sk.unique())))  \n",
    "    \n",
    "    for i in range(len(lislis_ESRD)):\n",
    "        if lislis_ESRD[i] <= datetime.timedelta(0):\n",
    "            patients_ESRD_labeled['time_to_event_ESRD'][i] = datetime.timedelta(0)\n",
    "            lislis_ESRD[i] = datetime.timedelta(0)\n",
    "    \n",
    "    time_to_event_ESRD_mean = np.mean(lislis_ESRD)\n",
    "    time_to_event_ESRD_median = np.median(lislis_ESRD)\n",
    "    time_to_event_ESRD_serror = np.std(lislis_ESRD, ddof=1)\n",
    "    \n",
    "        \n",
    "    \n",
    "    time_to_event_ESRD_mean_list.append(time_to_event_ESRD_mean)\n",
    "    time_to_event_ESRD_median_list.append(time_to_event_ESRD_median)\n",
    "    time_to_event_ESRD_serror_list.append(time_to_event_ESRD_serror)\n",
    "    \n",
    "    \n",
    "    time_to_event_dataset.append(patients_ESRD_labeled) \n",
    "    \n",
    "\n",
    "Sub_grouo_table['# of detected / sub-total'] = proportion_list\n",
    "Sub_grouo_table['Mu'] = mu_list\n",
    "Sub_grouo_table['Sigma'] = sigma_list\n",
    "Sub_grouo_table['Accuracy'] = Accuracy_list\n",
    "Sub_grouo_table['Sensitivity'] = Sensetivity_list\n",
    "Sub_grouo_table['Specificity'] = Specificity_list\n",
    "Sub_grouo_table['Mean time to event (ESRD diagnosis)'] = time_to_event_ESRD_mean_list\n",
    "Sub_grouo_table['Median time to event (ESRD diagnosis)'] = time_to_event_ESRD_median_list\n",
    "Sub_grouo_table['Standard error of time to event (ESRD diagnosis)'] = time_to_event_ESRD_serror_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset['time_to_event_ESRD'] = pd.to_timedelta(merged_dataset['time_to_event_ESRD'], errors='coerce')\n",
    "new_row = {'Sub groups':'Total','Mu':80.65333360443059 , 'Sigma':7.7797820957459045, 'Accuracy' : 0.8344949456145935, 'Sensitivity' : 0.9096118299445471, 'Specificity': 0.8297529726134494, 'Mean time to event (ESRD diagnosis)' : np.mean(merged_dataset.time_to_event_ESRD) , 'Median time to event (ESRD diagnosis)' : np.median(merged_dataset.time_to_event_ESRD)}\n",
    "Sub_grouo_table = Sub_grouo_table.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, working on time-to-event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item in time_to_event_dataset:\n",
    "    item.time_to_event_ESRD = pd.to_timedelta(item.time_to_event_ESRD, errors='coerce')\n",
    "\n",
    "time_to_event_dataset_Adults_under_65 = time_to_event_dataset[0].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Adults_above_65 = time_to_event_dataset[1].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Female = time_to_event_dataset[2].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Male = time_to_event_dataset[3].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_African_American = time_to_event_dataset[4].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_African_American = time_to_event_dataset[5].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Hypertension = time_to_event_dataset[6].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_Hypertension = time_to_event_dataset[7].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Diabetes = time_to_event_dataset[8].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_Diabetes = time_to_event_dataset[9].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Cardiovascular_Disease = time_to_event_dataset[10].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI','New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_Cardiovascular_Disease = time_to_event_dataset[11].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI','New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "\n",
    "time_to_event_dataset_Hypercholesterolemia = time_to_event_dataset[12].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)\n",
    "time_to_event_dataset_Non_Hypercholesterolemia = time_to_event_dataset[13].drop('Label', axis = 1).drop(['Trigger_date', 'eGFR_EPI', 'New_label', 'Diagnosis_admission_date_ESRD'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_event_Total = merged_dataset[['patient_sk', 'time_to_event_ESRD']]\n",
    "time_to_event_Total.time_to_event_ESRD = pd.to_timedelta(time_to_event_Total.time_to_event_ESRD, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISLIS = [[time_to_event_dataset_Adults_under_65, time_to_event_dataset_Adults_above_65], [time_to_event_dataset_Female, time_to_event_dataset_Male], [time_to_event_dataset_African_American, time_to_event_dataset_Non_African_American], [time_to_event_dataset_Hypertension, time_to_event_dataset_Non_Hypertension], [time_to_event_dataset_Diabetes, time_to_event_dataset_Non_Diabetes], [time_to_event_dataset_Cardiovascular_Disease, time_to_event_dataset_Non_Cardiovascular_Disease], [time_to_event_dataset_Hypercholesterolemia, time_to_event_dataset_Non_Hypercholesterolemia]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1: Chi square contingency test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "chi2_list = []\n",
    "p_value_list = []\n",
    "\n",
    "for thing in LISLIS:\n",
    "    item = thing[0]\n",
    "    Non_item = thing[1]\n",
    "    \n",
    "    a = item[item.time_to_event_ESRD > datetime.timedelta(0)].shape[0]\n",
    "    b = Non_item[Non_item.time_to_event_ESRD > datetime.timedelta(0)].shape[0]\n",
    "    c = item[item.time_to_event_ESRD == datetime.timedelta(0)].shape[0]\n",
    "    d = Non_item[Non_item.time_to_event_ESRD == datetime.timedelta(0)].shape[0]\n",
    "    \n",
    "    obs = np.array([[a, b], [c, d]])\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(obs, correction=False)\n",
    "    \n",
    "    chi2_list.append(chi2)\n",
    "    chi2_list.append(chi2)\n",
    "    p_value_list.append(p)\n",
    "    p_value_list.append(p)\n",
    "\n",
    "#total\n",
    "chi2_list.append('-')\n",
    "p_value_list.append('-')\n",
    "\n",
    "Sub_grouo_table['P Value - Chi2 (0.05)'] = p_value_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #2: t-student test with unequal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ttest_list = []\n",
    "p_value_list = []\n",
    "\n",
    "for thing in LISLIS:\n",
    "    item = thing[0]\n",
    "    Non_item = thing[1]\n",
    "    \n",
    "    a = item[np.isnan(item.time_to_event_ESRD) == False].time_to_event_ESRD.dt.total_seconds()\n",
    "    b = Non_item[np.isnan(Non_item.time_to_event_ESRD) == False].time_to_event_ESRD.dt.total_seconds()\n",
    "    \n",
    "    ttest, p = stats.ttest_ind(a, b, axis=0, equal_var=False)\n",
    "    \n",
    "    ttest_list.append(ttest)\n",
    "    ttest_list.append(ttest)\n",
    "    p_value_list.append(p)\n",
    "    p_value_list.append(p)\n",
    "\n",
    "#total\n",
    "ttest_list.append('-')\n",
    "p_value_list.append('-')\n",
    "\n",
    "Sub_grouo_table['P Value - t-test (0.05)'] = p_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_grouo_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For further information please contact rzz5164@psu.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
